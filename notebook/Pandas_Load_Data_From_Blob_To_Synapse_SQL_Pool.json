{
	"name": "Pandas_Load_Data_From_Blob_To_Synapse_SQL_Pool",
	"properties": {
		"description": "Load Data From Blob To Synapse SQL Pool",
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "1dbda91f-e1ab-424d-ada8-cf763bd43fdf"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"# Getiing the parameter value from the pipeline \r\n",
					"FolderName = \"2022_10\""
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Using the parameter value creating a new variables to use while reading the file\r\n",
					"FolderName_Without_Separator = FolderName.replace(\"_\", \"\")\r\n",
					"year = FolderName.split('_')[0]\r\n",
					"month = FolderName.split('_')[1]"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\r\n",
					"from pyspark.sql.functions import lit,col\r\n",
					"\r\n",
					"# Creating a spark session and connection to blob storage account\r\n",
					"blob_account_name = \"wendydlstorage\"\r\n",
					"blob_container_name = \"data\"\r\n",
					"sc = SparkSession.builder.getOrCreate()\r\n",
					"token_library = sc._jvm.com.microsoft.azure.synapse.tokenlibrary.TokenLibrary\r\n",
					"blob_sas_token = token_library.getConnectionString(\"AzureBlobStorage1\")\r\n",
					"spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Reading the first File (Analogue Reading File)\r\n",
					"FileName = 'wasbs://data@wendydlstorage.blob.core.windows.net/Bronze Layer/%s/P6523_Verbruiken_AMR_GEMEENTE_%s.csv' % (FolderName,FolderName_Without_Separator)\r\n",
					"df1 = spark.read.load(FileName, format='csv', header=True,delimiter=';',inferSchema=True)\r\n",
					"\r\n",
					"# Convert to pandas data frame\r\n",
					"df1 = df1.select(\"*\").toPandas()\r\n",
					"\r\n",
					"# Importing the libraries\r\n",
					"import pandas as pd\r\n",
					"import warnings\r\n",
					"warnings.filterwarnings('ignore')\r\n",
					"\r\n",
					"# Dropping the duplicates\r\n",
					"df1 = df1.drop_duplicates()\r\n",
					"\r\n",
					"# Selecting the required columns\r\n",
					"selected_df1 = df1[['Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente'\\\r\n",
					", 'WerkelijkVerbruik_RM_2017', 'BenaderendVerbruik_VM_2017', 'AantalToegangspunten_2017'\\\r\n",
					", 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018', 'AantalToegangspunten_2018'\\\r\n",
					", 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'AantalToegangspunten_2019'\\\r\n",
					", 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'AantalToegangspunten_2020'\\\r\n",
					", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'AantalToegangspunten_2021']]\r\n",
					"\r\n",
					"# Adding the additional calculated/custom columns\r\n",
					"selected_df1['MeasurementType'] = \"Analogue\"\r\n",
					"#selected_df1['MeasurementYear'] = year\r\n",
					"#selected_df1['MeasurementMonth'] = month\r\n",
					"\r\n",
					"# convert the date column to datetime\r\n",
					"try:\r\n",
					"    selected_df1['Peildatum'] = pd.to_datetime(selected_df1['Peildatum'], format='%d/%b/%y')\r\n",
					"except:\r\n",
					"    try:\r\n",
					"        selected_df1['Peildatum'] = pd.to_datetime(selected_df1['Peildatum'], format='%m/%d/%y')\r\n",
					"    except:\r\n",
					"        selected_df1['Peildatum'] = pd.to_datetime(selected_df1['Peildatum'], format='%d/%b/%Y')\r\n",
					"\r\n",
					"# convert the datetime object to the desired format\r\n",
					"selected_df1['Peildatum'] = selected_df1['Peildatum'].dt.strftime('%d-%m-%Y')\r\n",
					"\r\n",
					"selected_df1['BenaderendVerbruik_VM_2017_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2017\"]\r\n",
					"selected_df1['BenaderendVerbruik_VM_2018_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2018\"]\r\n",
					"selected_df1['BenaderendVerbruik_VM_2019_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2019\"]\r\n",
					"selected_df1['BenaderendVerbruik_VM_2020_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2020\"]\r\n",
					"selected_df1['BenaderendVerbruik_VM_2021_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2021\"]\r\n",
					"\r\n",
					"selected_df1['WerkelijkVerbruik_RM_2017'] = selected_df1['WerkelijkVerbruik_RM_2017'].str.replace(',','.')\r\n",
					"selected_df1['WerkelijkVerbruik_RM_2018'] = selected_df1['WerkelijkVerbruik_RM_2018'].str.replace(',','.')\r\n",
					"selected_df1['WerkelijkVerbruik_RM_2019'] = selected_df1['WerkelijkVerbruik_RM_2019'].str.replace(',','.')\r\n",
					"selected_df1['WerkelijkVerbruik_RM_2020'] = selected_df1['WerkelijkVerbruik_RM_2020'].str.replace(',','.')\r\n",
					"selected_df1['WerkelijkVerbruik_RM_2021'] = selected_df1['WerkelijkVerbruik_RM_2021'].str.replace(',','.')\r\n",
					"selected_df1['Gemiddeld_WerkelijkVerbruik'] = ((selected_df1['WerkelijkVerbruik_RM_2017'].astype(float)\\\r\n",
					"+ selected_df1['WerkelijkVerbruik_RM_2018'].astype(float) + selected_df1['WerkelijkVerbruik_RM_2019'].astype(float) + selected_df1['WerkelijkVerbruik_RM_2020'].astype(float)\\\r\n",
					"+ selected_df1['WerkelijkVerbruik_RM_2021'].astype(float))/5)\r\n",
					"\r\n",
					"selected_df1['BenaderendVerbruik_VM_2017'] = selected_df1['BenaderendVerbruik_VM_2017'].str.replace(',','.')\r\n",
					"selected_df1['BenaderendVerbruik_VM_2018'] = selected_df1['BenaderendVerbruik_VM_2018'].str.replace(',','.')\r\n",
					"selected_df1['BenaderendVerbruik_VM_2019'] = selected_df1['BenaderendVerbruik_VM_2019'].str.replace(',','.')\r\n",
					"selected_df1['BenaderendVerbruik_VM_2020'] = selected_df1['BenaderendVerbruik_VM_2020'].str.replace(',','.')\r\n",
					"selected_df1['BenaderendVerbruik_VM_2021'] = selected_df1['BenaderendVerbruik_VM_2021'].str.replace(',','.')\r\n",
					"selected_df1['Gemiddeld_BenaderendVerbruik'] = ((selected_df1['BenaderendVerbruik_VM_2017'].astype(float)\\\r\n",
					"+ selected_df1['BenaderendVerbruik_VM_2018'].astype(float) + selected_df1['BenaderendVerbruik_VM_2019'].astype(float) + selected_df1['BenaderendVerbruik_VM_2020'].astype(float)\\\r\n",
					"+ selected_df1['BenaderendVerbruik_VM_2021'].astype(float))/5)\r\n",
					"\r\n",
					"selected_df1['BenaderendVerbruik_VM_2017_Norm'] = selected_df1['BenaderendVerbruik_VM_2017_Norm'].str.replace(',','.')\r\n",
					"selected_df1['BenaderendVerbruik_VM_2018_Norm'] = selected_df1['BenaderendVerbruik_VM_2018_Norm'].str.replace(',','.')\r\n",
					"selected_df1['BenaderendVerbruik_VM_2019_Norm'] = selected_df1['BenaderendVerbruik_VM_2019_Norm'].str.replace(',','.')\r\n",
					"selected_df1['BenaderendVerbruik_VM_2020_Norm'] = selected_df1['BenaderendVerbruik_VM_2020_Norm'].str.replace(',','.')\r\n",
					"selected_df1['BenaderendVerbruik_VM_2021_Norm'] = selected_df1['BenaderendVerbruik_VM_2021_Norm'].str.replace(',','.')\r\n",
					"selected_df1['Gemiddeld_BenaderendVerbruik_Norm'] = ((selected_df1['BenaderendVerbruik_VM_2017_Norm'].astype(float)\\\r\n",
					"+ selected_df1['BenaderendVerbruik_VM_2018_Norm'].astype(float) + selected_df1['BenaderendVerbruik_VM_2019_Norm'].astype(float) + selected_df1['BenaderendVerbruik_VM_2020_Norm'].astype(float)\\\r\n",
					"+ selected_df1['BenaderendVerbruik_VM_2021_Norm'].astype(float))/5)\r\n",
					"\r\n",
					"selected_df1['Total_AantalToegangspunten'] = selected_df1['AantalToegangspunten_2017'].astype(float)\\\r\n",
					"+ selected_df1['AantalToegangspunten_2018'].astype(float) + selected_df1['AantalToegangspunten_2019'].astype(float) + selected_df1['AantalToegangspunten_2020'].astype(float)\\\r\n",
					"+ selected_df1['AantalToegangspunten_2021'].astype(float)\r\n",
					"\r\n",
					"# Rearrange the columns\r\n",
					"selected_df1 = selected_df1[['Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente', 'WerkelijkVerbruik_RM_2017'\\\r\n",
					", 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017', 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018'\\\r\n",
					", 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018', 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm'\\\r\n",
					", 'AantalToegangspunten_2019', 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
					", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021'\\\r\n",
					",'Gemiddeld_WerkelijkVerbruik','Gemiddeld_BenaderendVerbruik','Gemiddeld_BenaderendVerbruik_Norm','Total_AantalToegangspunten'\\\r\n",
					", 'MeasurementType']] #, 'MeasurementYear', 'MeasurementMonth'"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Checking the column names\r\n",
					"selected_df1.columns"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Selecting the top 5 rows\r\n",
					"selected_df1.head()"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": []
				},
				"source": [
					"\r\n",
					"# Reading the second File (Digital Reading File)\r\n",
					"FileName = 'wasbs://data@wendydlstorage.blob.core.windows.net/Bronze Layer/%s/P6523_Verbruiken_DM_GEMEENTE_%s.csv' % (FolderName,FolderName_Without_Separator)\r\n",
					"df2 = spark.read.load(FileName, format='csv', header=True,delimiter=';',inferSchema=True)\r\n",
					"\r\n",
					"# Convert to pandas data frame\r\n",
					"df2 = df2.select(\"*\").toPandas()\r\n",
					"\r\n",
					"# Dropping the duplicates\r\n",
					"df2 = df2.drop_duplicates()\r\n",
					"\r\n",
					"# Selecting the required columns\r\n",
					"selected_df2 = df2[['Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente'\\\r\n",
					", 'WerkelijkVerbruik_RM_2017', 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017'\\\r\n",
					", 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018', 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018'\\\r\n",
					", 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm', 'AantalToegangspunten_2019'\\\r\n",
					", 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
					", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021']]\r\n",
					"\r\n",
					"# Adding the additional calculated/custom columns\r\n",
					"selected_df2['MeasurementType'] = \"Analogue\"\r\n",
					"#selected_df2['MeasurementYear'] = year\r\n",
					"#selected_df2['MeasurementMonth'] = month\r\n",
					"\r\n",
					"# convert the date column to datetime\r\n",
					"# convert the date column to datetime\r\n",
					"try:\r\n",
					"    selected_df2['Peildatum'] = pd.to_datetime(selected_df2['Peildatum'], format='%d/%b/%y')\r\n",
					"except:\r\n",
					"    try:\r\n",
					"        selected_df2['Peildatum'] = pd.to_datetime(selected_df2['Peildatum'], format='%m/%d/%y')\r\n",
					"    except:\r\n",
					"        selected_df2['Peildatum'] = pd.to_datetime(selected_df2['Peildatum'], format='%d/%b/%Y')\r\n",
					"\r\n",
					"# convert the datetime object to the desired format\r\n",
					"selected_df2['Peildatum'] = selected_df2['Peildatum'].dt.strftime('%d-%m-%Y')\r\n",
					"\r\n",
					"\r\n",
					"selected_df2['WerkelijkVerbruik_RM_2017'] = selected_df2['WerkelijkVerbruik_RM_2017'].str.replace(',','.')\r\n",
					"selected_df2['WerkelijkVerbruik_RM_2018'] = selected_df2['WerkelijkVerbruik_RM_2018'].str.replace(',','.')\r\n",
					"selected_df2['WerkelijkVerbruik_RM_2019'] = selected_df2['WerkelijkVerbruik_RM_2019'].str.replace(',','.')\r\n",
					"selected_df2['WerkelijkVerbruik_RM_2020'] = selected_df2['WerkelijkVerbruik_RM_2020'].str.replace(',','.')\r\n",
					"selected_df2['WerkelijkVerbruik_RM_2021'] = selected_df2['WerkelijkVerbruik_RM_2021'].str.replace(',','.')\r\n",
					"selected_df2['Gemiddeld_WerkelijkVerbruik'] = ((selected_df2['WerkelijkVerbruik_RM_2017'].astype(float)\\\r\n",
					"+ selected_df2['WerkelijkVerbruik_RM_2018'].astype(float) + selected_df2['WerkelijkVerbruik_RM_2019'].astype(float) + selected_df2['WerkelijkVerbruik_RM_2020'].astype(float)\\\r\n",
					"+ selected_df2['WerkelijkVerbruik_RM_2021'].astype(float))/5)\r\n",
					"\r\n",
					"selected_df2['BenaderendVerbruik_VM_2017'] = selected_df2['BenaderendVerbruik_VM_2017'].str.replace(',','.')\r\n",
					"selected_df2['BenaderendVerbruik_VM_2018'] = selected_df2['BenaderendVerbruik_VM_2018'].str.replace(',','.')\r\n",
					"selected_df2['BenaderendVerbruik_VM_2019'] = selected_df2['BenaderendVerbruik_VM_2019'].str.replace(',','.')\r\n",
					"selected_df2['BenaderendVerbruik_VM_2020'] = selected_df2['BenaderendVerbruik_VM_2020'].str.replace(',','.')\r\n",
					"selected_df2['BenaderendVerbruik_VM_2021'] = selected_df2['BenaderendVerbruik_VM_2021'].str.replace(',','.')\r\n",
					"selected_df2['Gemiddeld_BenaderendVerbruik'] = ((selected_df2['BenaderendVerbruik_VM_2017'].astype(float)\\\r\n",
					"+ selected_df2['BenaderendVerbruik_VM_2018'].astype(float) + selected_df2['BenaderendVerbruik_VM_2019'].astype(float) + selected_df2['BenaderendVerbruik_VM_2020'].astype(float)\\\r\n",
					"+ selected_df2['BenaderendVerbruik_VM_2021'].astype(float))/5)\r\n",
					"\r\n",
					"selected_df2['BenaderendVerbruik_VM_2017_Norm'] = selected_df2['BenaderendVerbruik_VM_2017_Norm'].str.replace(',','.')\r\n",
					"selected_df2['BenaderendVerbruik_VM_2018_Norm'] = selected_df2['BenaderendVerbruik_VM_2018_Norm'].str.replace(',','.')\r\n",
					"selected_df2['BenaderendVerbruik_VM_2019_Norm'] = selected_df2['BenaderendVerbruik_VM_2019_Norm'].str.replace(',','.')\r\n",
					"selected_df2['BenaderendVerbruik_VM_2020_Norm'] = selected_df2['BenaderendVerbruik_VM_2020_Norm'].str.replace(',','.')\r\n",
					"selected_df2['BenaderendVerbruik_VM_2021_Norm'] = selected_df2['BenaderendVerbruik_VM_2021_Norm'].str.replace(',','.')\r\n",
					"selected_df2['Gemiddeld_BenaderendVerbruik_Norm'] = ((selected_df2['BenaderendVerbruik_VM_2017_Norm'].astype(float)\\\r\n",
					"+ selected_df2['BenaderendVerbruik_VM_2018_Norm'].astype(float) + selected_df2['BenaderendVerbruik_VM_2019_Norm'].astype(float) + selected_df2['BenaderendVerbruik_VM_2020_Norm'].astype(float)\\\r\n",
					"+ selected_df2['BenaderendVerbruik_VM_2021_Norm'].astype(float))/5)\r\n",
					"\r\n",
					"selected_df2['Total_AantalToegangspunten'] = selected_df2['AantalToegangspunten_2017'].astype(float)\\\r\n",
					"+ selected_df2['AantalToegangspunten_2018'].astype(float) + selected_df2['AantalToegangspunten_2019'].astype(float) + selected_df2['AantalToegangspunten_2020'].astype(float)\\\r\n",
					"+ selected_df2['AantalToegangspunten_2021'].astype(float)\r\n",
					"\r\n",
					"# Rearrange the columns\r\n",
					"selected_df2 = selected_df2[['Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente', 'WerkelijkVerbruik_RM_2017'\\\r\n",
					", 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017', 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018'\\\r\n",
					", 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018', 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm'\\\r\n",
					", 'AantalToegangspunten_2019', 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
					", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021'\\\r\n",
					",'Gemiddeld_WerkelijkVerbruik','Gemiddeld_BenaderendVerbruik','Gemiddeld_BenaderendVerbruik_Norm','Total_AantalToegangspunten'\\\r\n",
					", 'MeasurementType']] #, 'MeasurementYear', 'MeasurementMonth'"
				],
				"execution_count": 96
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Checking the column names\r\n",
					"selected_df2.columns"
				],
				"execution_count": 97
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Selecting the top 5 rows\r\n",
					"selected_df2.head()"
				],
				"execution_count": 98
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Checking the counts on each file\r\n",
					"print(selected_df1.shape[0]) #Analogue Reading - 2660\r\n",
					"print(selected_df2.shape[0]) #Digital Reading - 7005"
				],
				"execution_count": 99
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Creating a Group By to check the counts based on month, market and postal code\r\n",
					"grouped_data1 = selected_df1.groupby(['Peildatum', 'Markt', 'Leveringsadres_Postcode'])\r\n",
					"grouped_data2 = selected_df2.groupby(['Peildatum', 'Markt', 'Leveringsadres_Postcode'])\r\n",
					""
				],
				"execution_count": 100
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"count_group_by1 = grouped_data1.agg(\r\n",
					"    total_count=('WerkelijkVerbruik_RM_2017', 'count')\r\n",
					")\r\n",
					"count_group_by1.head() #Analogue Reading Group BY\r\n",
					""
				],
				"execution_count": 101
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"count_group_by2 = grouped_data2.agg(\r\n",
					"    total_count=('WerkelijkVerbruik_RM_2017', 'count')\r\n",
					")\r\n",
					"count_group_by2.head() #Digital Reading Group By"
				],
				"execution_count": 102
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Doing union operation to get a single dataframe combining Analogue and Digital measurement data\r\n",
					"df = pd.concat([selected_df2, selected_df1])"
				],
				"execution_count": 103
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df.head(5)"
				],
				"execution_count": 104
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df.dtypes"
				],
				"execution_count": 105
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"spark_df = spark.createDataFrame(df)"
				],
				"execution_count": 106
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"file_path = 'wasbs://data@wendydlstorage.blob.core.windows.net/Silver/Combined/Electricity_Measurement_2'\r\n",
					"write_format=\"delta\"\r\n",
					"partition_by=[\"Peildatum\"]\r\n",
					"mode_ = \"append\" #overwrite #append\r\n",
					"\r\n",
					"spark_df\\\r\n",
					".write\\\r\n",
					".option(\"header\", \"true\")\\\r\n",
					".option(\"overwriteSchema\", \"true\")\\\r\n",
					".format(write_format)\\\r\n",
					".partitionBy(partition_by)\\\r\n",
					".mode(mode_)\\\r\n",
					".save(file_path)"
				],
				"execution_count": 82
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Renaming the column names before join in order to avoid ambigious column names after the join\r\n",
					"selected_df1 = selected_df1.add_prefix('AM_')\r\n",
					"selected_df2 = selected_df2.add_prefix('DM_')\r\n",
					""
				],
				"execution_count": 107
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Doing a join operation to get a new data frame\r\n",
					"join_df = pd.merge(selected_df2, selected_df1, left_on=['DM_Markt', 'DM_Leveringsadres_Postcode','DM_Leveringsadres_Gemeente','DM_Peildatum'], right_on=['AM_Markt', 'AM_Leveringsadres_Postcode','AM_Leveringsadres_Gemeente','AM_Peildatum'], how='outer')\r\n",
					"\r\n",
					"\r\n",
					"# # Selecting the required columns after the join operation\r\n",
					"# join_df = join_df[['DM_Trekkingsdatum', 'DM_Peildatum', 'DM_Markt', 'DM_Leveringsadres_Postcode', 'DM_Leveringsadres_Gemeente'\\\r\n",
					"# , 'DM_WerkelijkVerbruik_RM_2017', 'DM_BenaderendVerbruik_VM_2017', 'DM_BenaderendVerbruik_VM_2017_Norm', 'DM_AantalToegangspunten_2017'\\\r\n",
					"# , 'AM_WerkelijkVerbruik_RM_2017', 'AM_BenaderendVerbruik_VM_2017', 'AM_BenaderendVerbruik_VM_2017_Norm', 'AM_AantalToegangspunten_2017'\\\r\n",
					"# , 'DM_WerkelijkVerbruik_RM_2018', 'DM_BenaderendVerbruik_VM_2018', 'DM_BenaderendVerbruik_VM_2018_Norm', 'DM_AantalToegangspunten_2018'\\\r\n",
					"# , 'AM_WerkelijkVerbruik_RM_2018', 'AM_BenaderendVerbruik_VM_2018', 'AM_BenaderendVerbruik_VM_2018_Norm', 'AM_AantalToegangspunten_2018'\\\r\n",
					"# , 'DM_WerkelijkVerbruik_RM_2019', 'DM_BenaderendVerbruik_VM_2019', 'DM_BenaderendVerbruik_VM_2019_Norm', 'DM_AantalToegangspunten_2019'\\\r\n",
					"# , 'AM_WerkelijkVerbruik_RM_2019', 'AM_BenaderendVerbruik_VM_2019', 'AM_BenaderendVerbruik_VM_2019_Norm', 'AM_AantalToegangspunten_2019'\\\r\n",
					"# , 'DM_WerkelijkVerbruik_RM_2020', 'DM_BenaderendVerbruik_VM_2020', 'DM_BenaderendVerbruik_VM_2020_Norm', 'DM_AantalToegangspunten_2020'\\\r\n",
					"# , 'AM_WerkelijkVerbruik_RM_2020', 'AM_BenaderendVerbruik_VM_2020', 'AM_BenaderendVerbruik_VM_2020_Norm', 'AM_AantalToegangspunten_2020'\\\r\n",
					"# , 'DM_WerkelijkVerbruik_RM_2021', 'DM_BenaderendVerbruik_VM_2021', 'DM_BenaderendVerbruik_VM_2021_Norm', 'DM_AantalToegangspunten_2021'\\\r\n",
					"# , 'AM_WerkelijkVerbruik_RM_2021', 'AM_BenaderendVerbruik_VM_2021', 'AM_BenaderendVerbruik_VM_2021_Norm', 'AM_AantalToegangspunten_2021'\\\r\n",
					"# , 'DM_Gemiddeld_WerkelijkVerbruik','DM_Gemiddeld_BenaderendVerbruik','DM_Gemiddeld_BenaderendVerbruik_Norm','DM_Total_AantalToegangspunten'\\\r\n",
					"# , 'AM_Gemiddeld_WerkelijkVerbruik','AM_Gemiddeld_BenaderendVerbruik','AM_Gemiddeld_BenaderendVerbruik_Norm','AM_Total_AantalToegangspunten'\r\n",
					"# , 'DM_MeasurementType']] #, 'DM_MeasurementYear', 'DM_MeasurementMonth'"
				],
				"execution_count": 109
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Printing the count of the join data frame\r\n",
					"join_df.shape[0]\r\n",
					""
				],
				"execution_count": 110
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Displaying the top 5 rows\r\n",
					"join_df.head(5)"
				],
				"execution_count": 111
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"spark_join_df = spark.createDataFrame(join_df)"
				],
				"execution_count": 112
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"file_path = 'wasbs://data@wendydlstorage.blob.core.windows.net/Silver/Combined/Electricity_Measurement_2_join'\r\n",
					"write_format=\"delta\"\r\n",
					"partition_by=[\"DM_Peildatum\"]\r\n",
					"mode_ = \"append\" #overwrite #append\r\n",
					"\r\n",
					"spark_join_df\\\r\n",
					".write\\\r\n",
					".option(\"header\", \"true\")\\\r\n",
					".option(\"overwriteSchema\", \"true\")\\\r\n",
					".format(write_format)\\\r\n",
					".partitionBy(partition_by)\\\r\n",
					".mode(mode_)\\\r\n",
					".save(file_path)"
				],
				"execution_count": 113
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				]
			}
		]
	}
}