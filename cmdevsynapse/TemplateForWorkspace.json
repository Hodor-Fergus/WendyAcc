{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "cmdevsynapse"
		},
		"cmdevsynapse-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'cmdevsynapse-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:cmdevsynapse.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"cmdevsynapse-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://rawdevstorage.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/Master_Pipeline')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Master Pipeline Which runs other pipeline",
				"activities": [
					{
						"name": "Execute Pyspark Pipeline",
						"description": "Execute Pyspark Pipeline",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Pyspark_STG_Load_To_Delta_Tables",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "Execute Pandas Pipeline",
						"description": "Execute Pandas Pipeline",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Execute Pyspark Pipeline",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Pandas_STG_Load_To_Delta_Tables",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "Wait for 5 sec",
						"description": "Wait for 5 sec\nThis is a random activity",
						"type": "Wait",
						"dependsOn": [
							{
								"activity": "Execute Pandas Pipeline",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"waitTimeInSeconds": 5
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Pyspark_STG_Load_To_Delta_Tables')]",
				"[concat(variables('workspaceId'), '/pipelines/Pandas_STG_Load_To_Delta_Tables')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pandas_STG_Load_To_Delta_Tables')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Pandas_STG_Load_To_Delta_Tables",
				"activities": [
					{
						"name": "Delete_Electricity_Measurement_pandas_union",
						"description": "Delete_Electricity_Measurement_pandas_union",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Electricity_Measurement_pandas_union",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Delete_Electricity_Measurement_pandas_join",
						"description": "Delete_Electricity_Measurement_pandas_join",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Electricity_Measurement_pandas_join",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Get Metadata of ADLS Data Source Container",
						"description": "Get Metadata of ADLS Data Source Container",
						"type": "GetMetadata",
						"dependsOn": [
							{
								"activity": "Delete_Electricity_Measurement_pandas_union",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Delete_Electricity_Measurement_pandas_join",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "ADLS_Container_rawdata",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach Container",
						"description": "ForEach Container",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata of ADLS Data Source Container",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata of ADLS Data Source Container').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Load the data from the blob container",
									"description": "Load the data from the blob container",
									"type": "SynapseNotebook",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"notebook": {
											"referenceName": "Pandas_Load_Data_From_Blob_To_Synapse_SQL_Pool",
											"type": "NotebookReference"
										},
										"parameters": {
											"FolderName": {
												"value": {
													"value": "@item()['name']",
													"type": "Expression"
												},
												"type": "string"
											}
										},
										"snapshot": true,
										"sparkPool": {
											"referenceName": "devpool",
											"type": "BigDataPoolReference"
										},
										"executorSize": "Small",
										"conf": {
											"spark.dynamicAllocation.enabled": false
										},
										"driverSize": "Small"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Electricity_Measurement_pandas_union')]",
				"[concat(variables('workspaceId'), '/datasets/Electricity_Measurement_pandas_join')]",
				"[concat(variables('workspaceId'), '/datasets/ADLS_Container_rawdata')]",
				"[concat(variables('workspaceId'), '/notebooks/Pandas_Load_Data_From_Blob_To_Synapse_SQL_Pool')]",
				"[concat(variables('workspaceId'), '/bigDataPools/devpool')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pyspark_STG_Load_To_Delta_Tables')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Pandas_STG_Load_To_Delta_Tables",
				"activities": [
					{
						"name": "Delete_Electricity_Measurement_pyspark_union",
						"description": "Delete_Electricity_Measurement_pyspark_union",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Electricity_Measurement_pyspark_union",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Delete_Electricity_Measurement_pyspark_join",
						"description": "Delete_Electricity_Measurement_pyspark_join",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Electricity_Measurement_pyspark_join",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Get Metadata of ADLS Data Source Container",
						"description": "Get Metadata of ADLS Data Source Container",
						"type": "GetMetadata",
						"dependsOn": [
							{
								"activity": "Delete_Electricity_Measurement_pyspark_union",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Delete_Electricity_Measurement_pyspark_join",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "ADLS_Container_rawdata",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach Container",
						"description": "ForEach Container",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata of ADLS Data Source Container",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata of ADLS Data Source Container').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Load the data from the blob container",
									"description": "Load the data from the blob container",
									"type": "SynapseNotebook",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"notebook": {
											"referenceName": "PySpark_Load_Data_From_Blob_To_Synapse_SQL_Pool",
											"type": "NotebookReference"
										},
										"parameters": {
											"FolderName": {
												"value": {
													"value": "@item()['name']",
													"type": "Expression"
												},
												"type": "string"
											}
										},
										"snapshot": true,
										"sparkPool": {
											"referenceName": "devpool",
											"type": "BigDataPoolReference"
										},
										"executorSize": "Small",
										"conf": {
											"spark.dynamicAllocation.enabled": false
										},
										"driverSize": "Small"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Electricity_Measurement_pyspark_union')]",
				"[concat(variables('workspaceId'), '/datasets/Electricity_Measurement_pyspark_join')]",
				"[concat(variables('workspaceId'), '/datasets/ADLS_Container_rawdata')]",
				"[concat(variables('workspaceId'), '/notebooks/PySpark_Load_Data_From_Blob_To_Synapse_SQL_Pool')]",
				"[concat(variables('workspaceId'), '/bigDataPools/devpool')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ADLS_Container_rawdata')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "cmdevsynapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileSystem": "rawdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/cmdevsynapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Electricity_Measurement_pandas_join')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "cmdevsynapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Electricity_Measurement_pandas_join",
						"fileSystem": "output"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/cmdevsynapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Electricity_Measurement_pandas_union')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "cmdevsynapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Electricity_Measurement_pandas_union",
						"fileSystem": "output"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/cmdevsynapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/cmdevsynapse-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('cmdevsynapse-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/cmdevsynapse-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('cmdevsynapse-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DeltaLakeQuery')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Other Queries"
				},
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n    Peildatum,MeasurementType, COUNT(*) as CT\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Silver/Combined/Electricity_Measurement_2/',\n        FORMAT = 'DELTA'\n    ) AS [result]\n\nGROUP BY Peildatum,MeasurementType\n\n\n\nSELECT\n    DM_Peildatum,DM_MeasurementType, COUNT(*) as CT\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Silver/Combined/Electricity_Measurement_join/',\n        FORMAT = 'DELTA'\n    ) AS [result]\n\nGROUP BY DM_Peildatum,DM_MeasurementType",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL _Load_Data_From_Blob_Join')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Main Queries"
				},
				"content": {
					"query": "-- Check the available database names\n--SELECT name, database_id, create_date  \n--FROM sys.databases;  \n--GO\n\n-- Change the databse collesion\n--alter database [default]\n--COLLATE Latin1_General_100_BIN2_UTF8;\n\n-- Main queries Inside CTE's to read data from CSV files from the ADLS\n;with cte_AMR_08 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    --,Sector,Graaddagen_RM,Graaddagen_VM_2017--,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018--,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019\n    --,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020--,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021--,Perc_Delta_VM_2021vsRM\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Analogue' as MeasurementType\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_08/P6523_Verbruiken_AMR_GEMEENTE_202208.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_DM_08 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    --,LP_Aanwezig,UNT_Aanwezig,SociaalTarief_Aanwezig,KlantFluvius,Graaddagen_RM,Graaddagen_VM_2017,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021,Perc_Delta_VM_2021vsRM\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Digital' as MeasurementType\n\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_08/P6523_Verbruiken_DM_GEMEENTE_202208.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_AMR_09 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    --,Sector,Graaddagen_RM,Graaddagen_VM_2017--,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018--,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019\n    --,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020--,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021--,Perc_Delta_VM_2021vsRM\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Analogue' as MeasurementType\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_09/P6523_Verbruiken_AMR_GEMEENTE_202209.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_DM_09 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    --,LP_Aanwezig,UNT_Aanwezig,SociaalTarief_Aanwezig,KlantFluvius,Graaddagen_RM,Graaddagen_VM_2017,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021,Perc_Delta_VM_2021vsRM\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Digital' as MeasurementType\n\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_09/P6523_Verbruiken_DM_GEMEENTE_202209.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_AMR_10 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    --,Sector,Graaddagen_RM,Graaddagen_VM_2017--,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018--,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019\n    --,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020--,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021--,Perc_Delta_VM_2021vsRM\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Analogue' as MeasurementType\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_10/P6523_Verbruiken_AMR_GEMEENTE_202210.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_DM_10 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    --,LP_Aanwezig,UNT_Aanwezig,SociaalTarief_Aanwezig,KlantFluvius,Graaddagen_RM,Graaddagen_VM_2017,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021,Perc_Delta_VM_2021vsRM\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Digital' as MeasurementType\n\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_10/P6523_Verbruiken_DM_GEMEENTE_202210.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_AMR_11 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    --,Sector,Graaddagen_RM,Graaddagen_VM_2017--,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018--,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019\n    --,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020--,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021--,Perc_Delta_VM_2021vsRM\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Analogue' as MeasurementType\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_11/P6523_Verbruiken_AMR_GEMEENTE_202211.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_DM_11 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    --,LP_Aanwezig,UNT_Aanwezig,SociaalTarief_Aanwezig,KlantFluvius,Graaddagen_RM,Graaddagen_VM_2017,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021,Perc_Delta_VM_2021vsRM\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Digital' as MeasurementType\n\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_11/P6523_Verbruiken_DM_GEMEENTE_202211.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,CTE_UNION_AMR as (\n    SELECT * FROM cte_AMR_08 UNION\n    SELECT * FROM cte_AMR_09 UNION\n    SELECT * FROM cte_AMR_10 UNION\n    SELECT * FROM cte_AMR_11\n)\n,CTE_UNION_DM as (\n    SELECT * FROM cte_DM_08 UNION\n    SELECT * FROM cte_DM_09 UNION\n    SELECT * FROM cte_DM_10 UNION\n    SELECT * FROM cte_DM_11\n)\n,CTE_JOIN as (\n    SELECT \n    A.Trekkingsdatum                        as AMR_Trekkingsdatum\n    ,A.Peildatum                            as AMR_Peildatum\n    ,A.Markt                                as AMR_Markt\n    ,A.Leveringsadres_Postcode              as AMR_Leveringsadres_Postcode\n    ,A.Leveringsadres_Gemeente              as AMR_Leveringsadres_Gemeente\n    ,A.WerkelijkVerbruik_RM_2017            as AMR_WerkelijkVerbruik_RM_2017\n    ,A.BenaderendVerbruik_VM_2017           as AMR_BenaderendVerbruik_VM_2017\n    ,A.BenaderendVerbruik_VM_2017_Norm      as AMR_BenaderendVerbruik_VM_2017_Norm\n    ,A.AantalToegangspunten_2017            as AMR_AantalToegangspunten_2017\n    ,A.WerkelijkVerbruik_RM_2018            as AMR_WerkelijkVerbruik_RM_2018\n    ,A.BenaderendVerbruik_VM_2018           as AMR_BenaderendVerbruik_VM_2018\n    ,A.BenaderendVerbruik_VM_2018_Norm      as AMR_BenaderendVerbruik_VM_2018_Norm\n    ,A.AantalToegangspunten_2018            as AMR_AantalToegangspunten_2018\n    ,A.WerkelijkVerbruik_RM_2019            as AMR_WerkelijkVerbruik_RM_2019\n    ,A.BenaderendVerbruik_VM_2019           as AMR_BenaderendVerbruik_VM_2019\n    ,A.BenaderendVerbruik_VM_2019_Norm      as AMR_BenaderendVerbruik_VM_2019_Norm\n    ,A.AantalToegangspunten_2019            as AMR_AantalToegangspunten_2019\n    ,A.WerkelijkVerbruik_RM_2020            as AMR_WerkelijkVerbruik_RM_2020\n    ,A.BenaderendVerbruik_VM_2020           as AMR_BenaderendVerbruik_VM_2020\n    ,A.BenaderendVerbruik_VM_2020_Norm      as AMR_BenaderendVerbruik_VM_2020_Norm\n    ,A.AantalToegangspunten_2020            as AMR_AantalToegangspunten_2020\n    ,A.WerkelijkVerbruik_RM_2021            as AMR_WerkelijkVerbruik_RM_2021\n    ,A.BenaderendVerbruik_VM_2021           as AMR_BenaderendVerbruik_VM_2021\n    ,A.BenaderendVerbruik_VM_2021_Norm      as AMR_BenaderendVerbruik_VM_2021_Norm\n    ,A.AantalToegangspunten_2021            as AMR_AantalToegangspunten_2021\n    ,A.Gemiddeld_WerkelijkVerbruik          as AMR_Gemiddeld_WerkelijkVerbruik\n    ,A.Gemiddeld_BenaderendVerbruik         as AMR_Gemiddeld_BenaderendVerbruik\n    ,A.Gemiddeld_BenaderendVerbruik_Norm    as AMR_Gemiddeld_BenaderendVerbruik_Norm\n    ,A.Total_AantalToegangspunten           as AMR_Total_AantalToegangspunten\n    ,A.MeasurementType                      as AMR_MeasurementType\n    ,B.Trekkingsdatum                       as DM_Trekkingsdatum\n    ,B.Peildatum                            as DM_Peildatum\n    ,B.Markt                                as DM_Markt\n    ,B.Leveringsadres_Postcode              as DM_Leveringsadres_Postcode\n    ,B.Leveringsadres_Gemeente              as DM_Leveringsadres_Gemeente\n    ,B.WerkelijkVerbruik_RM_2017            as DM_WerkelijkVerbruik_RM_2017\n    ,B.BenaderendVerbruik_VM_2017           as DM_BenaderendVerbruik_VM_2017\n    ,B.BenaderendVerbruik_VM_2017_Norm      as DM_BenaderendVerbruik_VM_2017_Norm\n    ,B.AantalToegangspunten_2017            as DM_AantalToegangspunten_2017\n    ,B.WerkelijkVerbruik_RM_2018            as DM_WerkelijkVerbruik_RM_2018\n    ,B.BenaderendVerbruik_VM_2018           as DM_BenaderendVerbruik_VM_2018\n    ,B.BenaderendVerbruik_VM_2018_Norm      as DM_BenaderendVerbruik_VM_2018_Norm\n    ,B.AantalToegangspunten_2018            as DM_AantalToegangspunten_2018\n    ,B.WerkelijkVerbruik_RM_2019            as DM_WerkelijkVerbruik_RM_2019\n    ,B.BenaderendVerbruik_VM_2019           as DM_BenaderendVerbruik_VM_2019\n    ,B.BenaderendVerbruik_VM_2019_Norm      as DM_BenaderendVerbruik_VM_2019_Norm\n    ,B.AantalToegangspunten_2019            as DM_AantalToegangspunten_2019\n    ,B.WerkelijkVerbruik_RM_2020            as DM_WerkelijkVerbruik_RM_2020\n    ,B.BenaderendVerbruik_VM_2020           as DM_BenaderendVerbruik_VM_2020\n    ,B.BenaderendVerbruik_VM_2020_Norm      as DM_BenaderendVerbruik_VM_2020_Norm\n    ,B.AantalToegangspunten_2020            as DM_AantalToegangspunten_2020\n    ,B.WerkelijkVerbruik_RM_2021            as DM_WerkelijkVerbruik_RM_2021\n    ,B.BenaderendVerbruik_VM_2021           as DM_BenaderendVerbruik_VM_2021\n    ,B.BenaderendVerbruik_VM_2021_Norm      as DM_BenaderendVerbruik_VM_2021_Norm\n    ,B.AantalToegangspunten_2021            as DM_AantalToegangspunten_2021\n    ,B.Gemiddeld_WerkelijkVerbruik          as DM_Gemiddeld_WerkelijkVerbruik\n    ,B.Gemiddeld_BenaderendVerbruik         as DM_Gemiddeld_BenaderendVerbruik\n    ,B.Gemiddeld_BenaderendVerbruik_Norm    as DM_Gemiddeld_BenaderendVerbruik_Norm\n    ,B.Total_AantalToegangspunten           as DM_Total_AantalToegangspunten\n    ,B.MeasurementType                      as DM_MeasurementType\n    FROM CTE_UNION_AMR A\n    FULL OUTER JOIN CTE_UNION_DM B ON A.Markt=B.Markt \n    AND A.Leveringsadres_Postcode=B.Leveringsadres_Postcode\n    AND A.Leveringsadres_Gemeente=B.Leveringsadres_Gemeente\n    AND A.Peildatum=B.Peildatum\n)\n\nSelect * \nFROM CTE_JOIN;\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL _Load_Data_From_Blob_Union')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Main Queries"
				},
				"content": {
					"query": "-- Check the available database names\n--SELECT name, database_id, create_date  \n--FROM sys.databases;  \n--GO\n\n-- Change the databse collesion\n--alter database [default]\n--COLLATE Latin1_General_100_BIN2_UTF8;\n\n-- Main queries Inside CTE's to read data from CSV files from the ADLS\n;with cte_AMR_08 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    --,Sector,Graaddagen_RM,Graaddagen_VM_2017--,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018--,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019\n    --,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020--,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021--,Perc_Delta_VM_2021vsRM\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Analogue' as MeasurementType\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_08/P6523_Verbruiken_AMR_GEMEENTE_202208.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_DM_08 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    --,LP_Aanwezig,UNT_Aanwezig,SociaalTarief_Aanwezig,KlantFluvius,Graaddagen_RM,Graaddagen_VM_2017,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021,Perc_Delta_VM_2021vsRM\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Digital' as MeasurementType\n\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_08/P6523_Verbruiken_DM_GEMEENTE_202208.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_AMR_09 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    --,Sector,Graaddagen_RM,Graaddagen_VM_2017--,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018--,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019\n    --,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020--,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021--,Perc_Delta_VM_2021vsRM\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Analogue' as MeasurementType\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_09/P6523_Verbruiken_AMR_GEMEENTE_202209.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_DM_09 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    --,LP_Aanwezig,UNT_Aanwezig,SociaalTarief_Aanwezig,KlantFluvius,Graaddagen_RM,Graaddagen_VM_2017,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021,Perc_Delta_VM_2021vsRM\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Digital' as MeasurementType\n\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_09/P6523_Verbruiken_DM_GEMEENTE_202209.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_AMR_10 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    --,Sector,Graaddagen_RM,Graaddagen_VM_2017--,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018--,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019\n    --,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020--,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021--,Perc_Delta_VM_2021vsRM\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Analogue' as MeasurementType\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_10/P6523_Verbruiken_AMR_GEMEENTE_202210.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_DM_10 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    --,LP_Aanwezig,UNT_Aanwezig,SociaalTarief_Aanwezig,KlantFluvius,Graaddagen_RM,Graaddagen_VM_2017,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021,Perc_Delta_VM_2021vsRM\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Digital' as MeasurementType\n\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_10/P6523_Verbruiken_DM_GEMEENTE_202210.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_AMR_11 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    --,Sector,Graaddagen_RM,Graaddagen_VM_2017--,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018--,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019\n    --,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020--,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021--,Perc_Delta_VM_2021vsRM\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Analogue' as MeasurementType\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_11/P6523_Verbruiken_AMR_GEMEENTE_202211.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,cte_DM_11 as (\nSELECT \n    Trekkingsdatum\n    ,CAST(Peildatum as DATE) as Peildatum\n    ,Markt\n    --,LP_Aanwezig,UNT_Aanwezig,SociaalTarief_Aanwezig,KlantFluvius,Graaddagen_RM,Graaddagen_VM_2017,Perc_Delta_VM_2017vsRM,Graaddagen_VM_2018,Perc_Delta_VM_2018vsRM,Graaddagen_VM_2019,Perc_Delta_VM_2019vsRM,Graaddagen_VM_2020,Perc_Delta_VM_2020vsRM,Graaddagen_VM_2021,Perc_Delta_VM_2021vsRM\n    ,CAST(Leveringsadres_Postcode as INT) as Leveringsadres_Postcode\n    ,Leveringsadres_Gemeente\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2017_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2017\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2018_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2018\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2019_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2019\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2020_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2020\n    ,CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)) as WerkelijkVerbruik_RM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021\n    ,CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)) as BenaderendVerbruik_VM_2021_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as AantalToegangspunten_2021   \n    ,(CAST(REPLACE(WerkelijkVerbruik_RM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(WerkelijkVerbruik_RM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_WerkelijkVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik\n    ,(CAST(REPLACE(BenaderendVerbruik_VM_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(BenaderendVerbruik_VM_2021,',','.') as DECIMAL(16,4)))/5 as Gemiddeld_BenaderendVerbruik_Norm\n    ,CAST(REPLACE(AantalToegangspunten_2017,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2018,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2019,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2020,',','.') as DECIMAL(16,4))+CAST(REPLACE(AantalToegangspunten_2021,',','.') as DECIMAL(16,4)) as Total_AantalToegangspunten\n    ,'Digital' as MeasurementType\n\nFROM\n    OPENROWSET(\n        BULK 'https://wendydlstorage.blob.core.windows.net/data/Bronze Layer/2022_11/P6523_Verbruiken_DM_GEMEENTE_202211.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        DELIMITER = ';',\n        HEADER_ROW = TRUE\n    ) AS [result]\n)\n,CTE_UNION_AMR as (\n    SELECT * FROM cte_AMR_08 UNION\n    SELECT * FROM cte_AMR_09 UNION\n    SELECT * FROM cte_AMR_10 UNION\n    SELECT * FROM cte_AMR_11\n)\n,CTE_UNION_DM as (\n    SELECT * FROM cte_DM_08 UNION\n    SELECT * FROM cte_DM_09 UNION\n    SELECT * FROM cte_DM_10 UNION\n    SELECT * FROM cte_DM_11\n)\n,CTE_UNION_ALL as (\n    SELECT * FROM CTE_UNION_AMR UNION\n    SELECT * FROM CTE_UNION_DM\n)\n\nSelect * \nFROM CTE_UNION_ALL;\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pandas_Load_Data_From_Blob_To_Synapse_SQL_Pool')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Load Data From Blob To Synapse SQL Pool",
				"folder": {
					"name": "Master Pipeline Notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "devpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "ea93f4b6-87ec-4307-b09e-5eb4d1fa8ccc"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/87083017-2c2b-47c8-8ea7-b4d36686fc97/resourceGroups/Dev_ResourceGroup/providers/Microsoft.Synapse/workspaces/cmdevsynapse/bigDataPools/devpool",
						"name": "devpool",
						"type": "Spark",
						"endpoint": "https://cmdevsynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/devpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"# Getiing the parameter value from the pipeline \r\n",
							"FolderName = \"2023_02\""
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Using the parameter value creating a new variables to use while reading the file\r\n",
							"FolderName_Without_Separator = FolderName.replace(\"_\", \"\")\r\n",
							"year = FolderName.split('_')[0]\r\n",
							"month = FolderName.split('_')[1]"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import SparkSession\r\n",
							"from pyspark.sql.functions import lit,col\r\n",
							"\r\n",
							"# Creating a spark session and connection to blob storage account\r\n",
							"blob_account_name = \"rawdevstorage\"\r\n",
							"blob_container_name = \"rawdata\"\r\n",
							"sc = SparkSession.builder.getOrCreate()\r\n",
							"token_library = sc._jvm.com.microsoft.azure.synapse.tokenlibrary.TokenLibrary\r\n",
							"blob_sas_token = token_library.getConnectionString(\"cmdevsynapse-WorkspaceDefaultStorage\")\r\n",
							"spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Create a dynamic column delimiter using regex for AMR\r\n",
							"import re\r\n",
							"def f_get_delimiter (source_path):\r\n",
							"    try:\r\n",
							"        headerlist = spark.sparkContext.textFile(source_path).take(1)\r\n",
							"        header_str = ''.join(headerlist)\r\n",
							"\r\n",
							"        results= re.search(\"(,|;|\\\\|)\",header_str)\r\n",
							"        return results.group()\r\n",
							"    except Exception as err:\r\n",
							"        print(\"Error Occured \", str(err))\r\n",
							"amr_Filename = 'abfss://rawdata@rawdevstorage.dfs.core.windows.net/%s/P6523_Verbruiken_AMR_GEMEENTE_%s.csv' % (FolderName, FolderName_Without_Separator)\r\n",
							"amr_delimiter_type = (f_get_delimiter(amr_Filename))"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Reading the first File (Analogue Reading File)\r\n",
							"FileName = 'abfss://rawdata@rawdevstorage.dfs.core.windows.net/%s/P6523_Verbruiken_AMR_GEMEENTE_%s.csv' % (FolderName,FolderName_Without_Separator)\r\n",
							"df1 = spark.read.load(FileName, format='csv', header=True,delimiter=amr_delimiter_type,inferSchema=True)\r\n",
							"\r\n",
							"# Convert to pandas data frame\r\n",
							"df1 = df1.select(\"*\").toPandas()\r\n",
							"\r\n",
							"# Importing the libraries\r\n",
							"import pandas as pd\r\n",
							"import warnings\r\n",
							"warnings.filterwarnings('ignore')\r\n",
							"\r\n",
							"# Dropping the duplicates\r\n",
							"df1 = df1.drop_duplicates()\r\n",
							"\r\n",
							"# Selecting the required columns\r\n",
							"selected_df1 = df1[['Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente'\\\r\n",
							", 'WerkelijkVerbruik_RM_2017', 'BenaderendVerbruik_VM_2017', 'AantalToegangspunten_2017'\\\r\n",
							", 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018', 'AantalToegangspunten_2018'\\\r\n",
							", 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'AantalToegangspunten_2019'\\\r\n",
							", 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'AantalToegangspunten_2020'\\\r\n",
							", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'AantalToegangspunten_2021']]\r\n",
							"\r\n",
							"# Adding the additional calculated/custom columns\r\n",
							"selected_df1['MeasurementType'] = \"Analogue\"\r\n",
							"#selected_df1['MeasurementYear'] = year\r\n",
							"#selected_df1['MeasurementMonth'] = month\r\n",
							"\r\n",
							"# convert the date column to datetime\r\n",
							"try:\r\n",
							"    selected_df1['Peildatum'] = pd.to_datetime(selected_df1['Peildatum'], format='%d/%b/%y')\r\n",
							"except:\r\n",
							"    try:\r\n",
							"        selected_df1['Peildatum'] = pd.to_datetime(selected_df1['Peildatum'], format='%m/%d/%y')\r\n",
							"    except:\r\n",
							"        try:\r\n",
							"            selected_df1['Peildatum'] = pd.to_datetime(selected_df1['Peildatum'], format='%d/%b/%Y')\r\n",
							"        except:\r\n",
							"            selected_df1['Peildatum'] = pd.to_datetime(selected_df1['Peildatum'], format='%d-%b-%y')\r\n",
							"\r\n",
							"# convert the datetime object to the desired format\r\n",
							"selected_df1['Peildatum'] = selected_df1['Peildatum'].dt.strftime('%d-%m-%Y')\r\n",
							"\r\n",
							"selected_df1['BenaderendVerbruik_VM_2017_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2017\"]\r\n",
							"selected_df1['BenaderendVerbruik_VM_2018_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2018\"]\r\n",
							"selected_df1['BenaderendVerbruik_VM_2019_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2019\"]\r\n",
							"selected_df1['BenaderendVerbruik_VM_2020_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2020\"]\r\n",
							"selected_df1['BenaderendVerbruik_VM_2021_Norm'] = selected_df1[\"BenaderendVerbruik_VM_2021\"]\r\n",
							"\r\n",
							"selected_df1['WerkelijkVerbruik_RM_2017'] = selected_df1['WerkelijkVerbruik_RM_2017'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['WerkelijkVerbruik_RM_2018'] = selected_df1['WerkelijkVerbruik_RM_2018'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['WerkelijkVerbruik_RM_2019'] = selected_df1['WerkelijkVerbruik_RM_2019'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['WerkelijkVerbruik_RM_2020'] = selected_df1['WerkelijkVerbruik_RM_2020'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['WerkelijkVerbruik_RM_2021'] = selected_df1['WerkelijkVerbruik_RM_2021'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['Gemiddeld_WerkelijkVerbruik'] = ((selected_df1['WerkelijkVerbruik_RM_2017'].astype(float)\\\r\n",
							"+ selected_df1['WerkelijkVerbruik_RM_2018'].astype(float) + selected_df1['WerkelijkVerbruik_RM_2019'].astype(float) + selected_df1['WerkelijkVerbruik_RM_2020'].astype(float)\\\r\n",
							"+ selected_df1['WerkelijkVerbruik_RM_2021'].astype(float))/5)\r\n",
							"\r\n",
							"selected_df1['BenaderendVerbruik_VM_2017'] = selected_df1['BenaderendVerbruik_VM_2017'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['BenaderendVerbruik_VM_2018'] = selected_df1['BenaderendVerbruik_VM_2018'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['BenaderendVerbruik_VM_2019'] = selected_df1['BenaderendVerbruik_VM_2019'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['BenaderendVerbruik_VM_2020'] = selected_df1['BenaderendVerbruik_VM_2020'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['BenaderendVerbruik_VM_2021'] = selected_df1['BenaderendVerbruik_VM_2021'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['Gemiddeld_BenaderendVerbruik'] = ((selected_df1['BenaderendVerbruik_VM_2017'].astype(float)\\\r\n",
							"+ selected_df1['BenaderendVerbruik_VM_2018'].astype(float) + selected_df1['BenaderendVerbruik_VM_2019'].astype(float) + selected_df1['BenaderendVerbruik_VM_2020'].astype(float)\\\r\n",
							"+ selected_df1['BenaderendVerbruik_VM_2021'].astype(float))/5)\r\n",
							"\r\n",
							"selected_df1['BenaderendVerbruik_VM_2017_Norm'] = selected_df1['BenaderendVerbruik_VM_2017_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['BenaderendVerbruik_VM_2018_Norm'] = selected_df1['BenaderendVerbruik_VM_2018_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['BenaderendVerbruik_VM_2019_Norm'] = selected_df1['BenaderendVerbruik_VM_2019_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['BenaderendVerbruik_VM_2020_Norm'] = selected_df1['BenaderendVerbruik_VM_2020_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['BenaderendVerbruik_VM_2021_Norm'] = selected_df1['BenaderendVerbruik_VM_2021_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df1['Gemiddeld_BenaderendVerbruik_Norm'] = ((selected_df1['BenaderendVerbruik_VM_2017_Norm'].astype(float)\\\r\n",
							"+ selected_df1['BenaderendVerbruik_VM_2018_Norm'].astype(float) + selected_df1['BenaderendVerbruik_VM_2019_Norm'].astype(float) + selected_df1['BenaderendVerbruik_VM_2020_Norm'].astype(float)\\\r\n",
							"+ selected_df1['BenaderendVerbruik_VM_2021_Norm'].astype(float))/5)\r\n",
							"\r\n",
							"selected_df1['Total_AantalToegangspunten'] = selected_df1['AantalToegangspunten_2017'].astype(float)\\\r\n",
							"+ selected_df1['AantalToegangspunten_2018'].astype(float) + selected_df1['AantalToegangspunten_2019'].astype(float) + selected_df1['AantalToegangspunten_2020'].astype(float)\\\r\n",
							"+ selected_df1['AantalToegangspunten_2021'].astype(float)\r\n",
							"\r\n",
							"# Rearrange the columns\r\n",
							"selected_df1 = selected_df1[['Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente', 'WerkelijkVerbruik_RM_2017'\\\r\n",
							", 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017', 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018'\\\r\n",
							", 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018', 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm'\\\r\n",
							", 'AantalToegangspunten_2019', 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
							", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021'\\\r\n",
							",'Gemiddeld_WerkelijkVerbruik','Gemiddeld_BenaderendVerbruik','Gemiddeld_BenaderendVerbruik_Norm','Total_AantalToegangspunten'\\\r\n",
							", 'MeasurementType']] #, 'MeasurementYear', 'MeasurementMonth'"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Checking the column names\r\n",
							"selected_df1.columns"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Selecting the top 5 rows\r\n",
							"selected_df1.head()"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Create a dynamic column delimiter using regex for DM\r\n",
							"import re\r\n",
							"def f_get_delimiter (source_path):\r\n",
							"    try:\r\n",
							"        headerlist = spark.sparkContext.textFile(source_path).take(1)\r\n",
							"        header_str = ''.join(headerlist)\r\n",
							"\r\n",
							"        results= re.search(\"(,|;|\\\\|)\",header_str)\r\n",
							"        return results.group()\r\n",
							"    except Exception as err:\r\n",
							"        print(\"Error Occured \", str(err))\r\n",
							"amr_Filename = 'abfss://rawdata@rawdevstorage.dfs.core.windows.net/%s/P6523_Verbruiken_DM_GEMEENTE_%s.csv' % (FolderName, FolderName_Without_Separator)\r\n",
							"amr_delimiter_type = (f_get_delimiter(amr_Filename))"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": []
						},
						"source": [
							"\r\n",
							"# Reading the second File (Digital Reading File)\r\n",
							"FileName = 'abfss://rawdata@rawdevstorage.dfs.core.windows.net/%s/P6523_Verbruiken_DM_GEMEENTE_%s.csv' % (FolderName,FolderName_Without_Separator)\r\n",
							"df2 = spark.read.load(FileName, format='csv', header=True,delimiter=amr_delimiter_type,inferSchema=True)\r\n",
							"\r\n",
							"# Convert to pandas data frame\r\n",
							"df2 = df2.select(\"*\").toPandas()\r\n",
							"\r\n",
							"# Dropping the duplicates\r\n",
							"df2 = df2.drop_duplicates()\r\n",
							"\r\n",
							"# Selecting the required columns\r\n",
							"selected_df2 = df2[['Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente'\\\r\n",
							", 'WerkelijkVerbruik_RM_2017', 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017'\\\r\n",
							", 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018', 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018'\\\r\n",
							", 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm', 'AantalToegangspunten_2019'\\\r\n",
							", 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
							", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021']]\r\n",
							"\r\n",
							"# Adding the additional calculated/custom columns\r\n",
							"selected_df2['MeasurementType'] = \"Analogue\"\r\n",
							"#selected_df2['MeasurementYear'] = year\r\n",
							"#selected_df2['MeasurementMonth'] = month\r\n",
							"\r\n",
							"# convert the date column to datetime\r\n",
							"# convert the date column to datetime\r\n",
							"try:\r\n",
							"    selected_df2['Peildatum'] = pd.to_datetime(selected_df2['Peildatum'], format='%d/%b/%y')\r\n",
							"except:\r\n",
							"    try:\r\n",
							"        selected_df2['Peildatum'] = pd.to_datetime(selected_df2['Peildatum'], format='%m/%d/%y')\r\n",
							"    except:\r\n",
							"        try:\r\n",
							"            selected_df2['Peildatum'] = pd.to_datetime(selected_df2['Peildatum'], format='%d/%b/%Y')\r\n",
							"        except:\r\n",
							"            selected_df2['Peildatum'] = pd.to_datetime(selected_df2['Peildatum'], format='%d-%b-%y')\r\n",
							"\r\n",
							"# convert the datetime object to the desired format\r\n",
							"selected_df2['Peildatum'] = selected_df2['Peildatum'].dt.strftime('%d-%m-%Y')\r\n",
							"\r\n",
							"\r\n",
							"selected_df2['WerkelijkVerbruik_RM_2017'] = selected_df2['WerkelijkVerbruik_RM_2017'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['WerkelijkVerbruik_RM_2018'] = selected_df2['WerkelijkVerbruik_RM_2018'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['WerkelijkVerbruik_RM_2019'] = selected_df2['WerkelijkVerbruik_RM_2019'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['WerkelijkVerbruik_RM_2020'] = selected_df2['WerkelijkVerbruik_RM_2020'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['WerkelijkVerbruik_RM_2021'] = selected_df2['WerkelijkVerbruik_RM_2021'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['Gemiddeld_WerkelijkVerbruik'] = ((selected_df2['WerkelijkVerbruik_RM_2017'].astype(float)\\\r\n",
							"+ selected_df2['WerkelijkVerbruik_RM_2018'].astype(float) + selected_df2['WerkelijkVerbruik_RM_2019'].astype(float) + selected_df2['WerkelijkVerbruik_RM_2020'].astype(float)\\\r\n",
							"+ selected_df2['WerkelijkVerbruik_RM_2021'].astype(float))/5)\r\n",
							"\r\n",
							"selected_df2['BenaderendVerbruik_VM_2017'] = selected_df2['BenaderendVerbruik_VM_2017'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['BenaderendVerbruik_VM_2018'] = selected_df2['BenaderendVerbruik_VM_2018'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['BenaderendVerbruik_VM_2019'] = selected_df2['BenaderendVerbruik_VM_2019'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['BenaderendVerbruik_VM_2020'] = selected_df2['BenaderendVerbruik_VM_2020'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['BenaderendVerbruik_VM_2021'] = selected_df2['BenaderendVerbruik_VM_2021'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['Gemiddeld_BenaderendVerbruik'] = ((selected_df2['BenaderendVerbruik_VM_2017'].astype(float)\\\r\n",
							"+ selected_df2['BenaderendVerbruik_VM_2018'].astype(float) + selected_df2['BenaderendVerbruik_VM_2019'].astype(float) + selected_df2['BenaderendVerbruik_VM_2020'].astype(float)\\\r\n",
							"+ selected_df2['BenaderendVerbruik_VM_2021'].astype(float))/5)\r\n",
							"\r\n",
							"selected_df2['BenaderendVerbruik_VM_2017_Norm'] = selected_df2['BenaderendVerbruik_VM_2017_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['BenaderendVerbruik_VM_2018_Norm'] = selected_df2['BenaderendVerbruik_VM_2018_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['BenaderendVerbruik_VM_2019_Norm'] = selected_df2['BenaderendVerbruik_VM_2019_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['BenaderendVerbruik_VM_2020_Norm'] = selected_df2['BenaderendVerbruik_VM_2020_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['BenaderendVerbruik_VM_2021_Norm'] = selected_df2['BenaderendVerbruik_VM_2021_Norm'].astype(str).str.replace(',','.')\r\n",
							"selected_df2['Gemiddeld_BenaderendVerbruik_Norm'] = ((selected_df2['BenaderendVerbruik_VM_2017_Norm'].astype(float)\\\r\n",
							"+ selected_df2['BenaderendVerbruik_VM_2018_Norm'].astype(float) + selected_df2['BenaderendVerbruik_VM_2019_Norm'].astype(float) + selected_df2['BenaderendVerbruik_VM_2020_Norm'].astype(float)\\\r\n",
							"+ selected_df2['BenaderendVerbruik_VM_2021_Norm'].astype(float))/5)\r\n",
							"\r\n",
							"selected_df2['Total_AantalToegangspunten'] = selected_df2['AantalToegangspunten_2017'].astype(float)\\\r\n",
							"+ selected_df2['AantalToegangspunten_2018'].astype(float) + selected_df2['AantalToegangspunten_2019'].astype(float) + selected_df2['AantalToegangspunten_2020'].astype(float)\\\r\n",
							"+ selected_df2['AantalToegangspunten_2021'].astype(float)\r\n",
							"\r\n",
							"# Rearrange the columns\r\n",
							"selected_df2 = selected_df2[['Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente', 'WerkelijkVerbruik_RM_2017'\\\r\n",
							", 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017', 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018'\\\r\n",
							", 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018', 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm'\\\r\n",
							", 'AantalToegangspunten_2019', 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
							", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021'\\\r\n",
							",'Gemiddeld_WerkelijkVerbruik','Gemiddeld_BenaderendVerbruik','Gemiddeld_BenaderendVerbruik_Norm','Total_AantalToegangspunten'\\\r\n",
							", 'MeasurementType']] #, 'MeasurementYear', 'MeasurementMonth'"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Checking the column names\r\n",
							"selected_df2.columns"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Selecting the top 5 rows\r\n",
							"selected_df2.head()"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Checking the counts on each file\r\n",
							"print(selected_df1.shape[0]) #Analogue Reading - 2660\r\n",
							"print(selected_df2.shape[0]) #Digital Reading - 7005"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Creating a Group By to check the counts based on month, market and postal code\r\n",
							"grouped_data1 = selected_df1.groupby(['Peildatum', 'Markt', 'Leveringsadres_Postcode'])\r\n",
							"grouped_data2 = selected_df2.groupby(['Peildatum', 'Markt', 'Leveringsadres_Postcode'])\r\n",
							""
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"count_group_by1 = grouped_data1.agg(\r\n",
							"    total_count=('WerkelijkVerbruik_RM_2017', 'count')\r\n",
							")\r\n",
							"count_group_by1.head() #Analogue Reading Group BY\r\n",
							""
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"count_group_by2 = grouped_data2.agg(\r\n",
							"    total_count=('WerkelijkVerbruik_RM_2017', 'count')\r\n",
							")\r\n",
							"count_group_by2.head() #Digital Reading Group By"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Doing union operation to get a single dataframe combining Analogue and Digital measurement data\r\n",
							"df = pd.concat([selected_df2, selected_df1])"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df.head(5)"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.dtypes"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"spark_df = spark.createDataFrame(df)"
						],
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"file_path = 'abfss://output@rawdevstorage.dfs.core.windows.net/Electricity_Measurement_pandas_union'\r\n",
							"write_format=\"delta\"\r\n",
							"partition_by=[\"Peildatum\"]\r\n",
							"mode_ = \"append\" #overwrite #append\r\n",
							"\r\n",
							"spark_df\\\r\n",
							".write\\\r\n",
							".option(\"header\", \"true\")\\\r\n",
							".option(\"overwriteSchema\", \"true\")\\\r\n",
							".format(write_format)\\\r\n",
							".partitionBy(partition_by)\\\r\n",
							".mode(mode_)\\\r\n",
							".save(file_path)"
						],
						"outputs": [],
						"execution_count": 29
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Renaming the column names before join in order to avoid ambigious column names after the join\r\n",
							"selected_df1 = selected_df1.add_prefix('AM_')\r\n",
							"selected_df2 = selected_df2.add_prefix('DM_')\r\n",
							""
						],
						"outputs": [],
						"execution_count": 30
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Doing a join operation to get a new data frame\r\n",
							"join_df = pd.merge(selected_df2, selected_df1, left_on=['DM_Markt', 'DM_Leveringsadres_Postcode','DM_Leveringsadres_Gemeente','DM_Peildatum'], right_on=['AM_Markt', 'AM_Leveringsadres_Postcode','AM_Leveringsadres_Gemeente','AM_Peildatum'], how='outer')\r\n",
							"\r\n",
							"\r\n",
							"# # Selecting the required columns after the join operation\r\n",
							"# join_df = join_df[['DM_Trekkingsdatum', 'DM_Peildatum', 'DM_Markt', 'DM_Leveringsadres_Postcode', 'DM_Leveringsadres_Gemeente'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2017', 'DM_BenaderendVerbruik_VM_2017', 'DM_BenaderendVerbruik_VM_2017_Norm', 'DM_AantalToegangspunten_2017'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2017', 'AM_BenaderendVerbruik_VM_2017', 'AM_BenaderendVerbruik_VM_2017_Norm', 'AM_AantalToegangspunten_2017'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2018', 'DM_BenaderendVerbruik_VM_2018', 'DM_BenaderendVerbruik_VM_2018_Norm', 'DM_AantalToegangspunten_2018'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2018', 'AM_BenaderendVerbruik_VM_2018', 'AM_BenaderendVerbruik_VM_2018_Norm', 'AM_AantalToegangspunten_2018'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2019', 'DM_BenaderendVerbruik_VM_2019', 'DM_BenaderendVerbruik_VM_2019_Norm', 'DM_AantalToegangspunten_2019'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2019', 'AM_BenaderendVerbruik_VM_2019', 'AM_BenaderendVerbruik_VM_2019_Norm', 'AM_AantalToegangspunten_2019'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2020', 'DM_BenaderendVerbruik_VM_2020', 'DM_BenaderendVerbruik_VM_2020_Norm', 'DM_AantalToegangspunten_2020'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2020', 'AM_BenaderendVerbruik_VM_2020', 'AM_BenaderendVerbruik_VM_2020_Norm', 'AM_AantalToegangspunten_2020'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2021', 'DM_BenaderendVerbruik_VM_2021', 'DM_BenaderendVerbruik_VM_2021_Norm', 'DM_AantalToegangspunten_2021'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2021', 'AM_BenaderendVerbruik_VM_2021', 'AM_BenaderendVerbruik_VM_2021_Norm', 'AM_AantalToegangspunten_2021'\\\r\n",
							"# , 'DM_Gemiddeld_WerkelijkVerbruik','DM_Gemiddeld_BenaderendVerbruik','DM_Gemiddeld_BenaderendVerbruik_Norm','DM_Total_AantalToegangspunten'\\\r\n",
							"# , 'AM_Gemiddeld_WerkelijkVerbruik','AM_Gemiddeld_BenaderendVerbruik','AM_Gemiddeld_BenaderendVerbruik_Norm','AM_Total_AantalToegangspunten'\r\n",
							"# , 'DM_MeasurementType']] #, 'DM_MeasurementYear', 'DM_MeasurementMonth'"
						],
						"outputs": [],
						"execution_count": 31
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Printing the count of the join data frame\r\n",
							"join_df.shape[0]\r\n",
							""
						],
						"outputs": [],
						"execution_count": 32
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Displaying the top 5 rows\r\n",
							"join_df.head(5)"
						],
						"outputs": [],
						"execution_count": 33
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"spark_join_df = spark.createDataFrame(join_df)"
						],
						"outputs": [],
						"execution_count": 34
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"file_path = 'abfss://output@rawdevstorage.dfs.core.windows.net/Electricity_Measurement_pandas_join'\r\n",
							"write_format=\"delta\"\r\n",
							"partition_by=[\"DM_Peildatum\"]\r\n",
							"mode_ = \"append\" #overwrite #append\r\n",
							"\r\n",
							"spark_join_df\\\r\n",
							".write\\\r\n",
							".option(\"header\", \"true\")\\\r\n",
							".option(\"overwriteSchema\", \"true\")\\\r\n",
							".format(write_format)\\\r\n",
							".partitionBy(partition_by)\\\r\n",
							".mode(mode_)\\\r\n",
							".save(file_path)"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PySpark_Load_Data_From_Blob_To_Synapse_SQL_Pool')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Load Data From Blob To Synapse SQL Pool",
				"folder": {
					"name": "Master Pipeline Notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "devpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "27402296-0bc2-41c8-9843-619e8feaacf8"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/87083017-2c2b-47c8-8ea7-b4d36686fc97/resourceGroups/Dev_ResourceGroup/providers/Microsoft.Synapse/workspaces/cmdevsynapse/bigDataPools/devpool",
						"name": "devpool",
						"type": "Spark",
						"endpoint": "https://cmdevsynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/devpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"# Getiing the parameter value from the pipeline \r\n",
							"FolderName = \"2022_10\""
						],
						"outputs": [],
						"execution_count": 73
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Using the parameter value creating a new variables to use while reading the file\r\n",
							"FolderName_Without_Separator = FolderName.replace(\"_\", \"\")\r\n",
							"year = FolderName.split('_')[0]\r\n",
							"month = FolderName.split('_')[1]"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\r\n",
							"# Creating a spark session and connection to blob storage account\r\n",
							"blob_account_name = \"rawdevstorage\"\r\n",
							"blob_container_name = \"rawdata\"\r\n",
							"from pyspark.sql import SparkSession\r\n",
							"from pyspark.sql.functions import lit,col,sum,mean,regexp_replace,to_date\r\n",
							"from pyspark.sql.types import DateType\r\n",
							"\r\n",
							"sc = SparkSession.builder.getOrCreate()\r\n",
							"token_library = sc._jvm.com.microsoft.azure.synapse.tokenlibrary.TokenLibrary\r\n",
							"blob_sas_token = token_library.getConnectionString(\"cmdevsynapse-WorkspaceDefaultStorage\")\r\n",
							"spark.conf.set(\r\n",
							"    'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\r\n",
							"    blob_sas_token)"
						],
						"outputs": [],
						"execution_count": 57
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Create a dynamic column delimiter using regex for AMR\r\n",
							"import re\r\n",
							"def f_get_delimiter (source_path):\r\n",
							"    try:\r\n",
							"        headerlist = spark.sparkContext.textFile(source_path).take(1)\r\n",
							"        header_str = ''.join(headerlist)\r\n",
							"\r\n",
							"        results= re.search(\"(,|;|\\\\|)\",header_str)\r\n",
							"        return results.group()\r\n",
							"    except Exception as err:\r\n",
							"        print(\"Error Occured \", str(err))\r\n",
							"amr_Filename = 'abfss://rawdata@rawdevstorage.dfs.core.windows.net/%s/P6523_Verbruiken_AMR_GEMEENTE_%s.csv' % (FolderName, FolderName_Without_Separator)\r\n",
							"amr_delimiter_type = (f_get_delimiter(amr_Filename))"
						],
						"outputs": [],
						"execution_count": 58
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"\r\n",
							"# Reading the first File (Analogue Reading File)\r\n",
							"FileName = 'abfss://rawdata@rawdevstorage.dfs.core.windows.net/%s/P6523_Verbruiken_AMR_GEMEENTE_%s.csv' % (FolderName,FolderName_Without_Separator)\r\n",
							"df1 = spark.read.load(FileName, format='csv', header=True,delimiter=amr_delimiter_type,inferSchema=True)\r\n",
							"\r\n",
							"# Remove duplicates\r\n",
							"df1 = df1.dropDuplicates()\r\n",
							"\r\n",
							"# Selecting the required columns\r\n",
							"selected_df1 = df1.select('Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente'\\\r\n",
							", 'WerkelijkVerbruik_RM_2017', 'BenaderendVerbruik_VM_2017', 'AantalToegangspunten_2017'\\\r\n",
							", 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018', 'AantalToegangspunten_2018'\\\r\n",
							", 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'AantalToegangspunten_2019'\\\r\n",
							", 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'AantalToegangspunten_2020'\\\r\n",
							", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'AantalToegangspunten_2021')\r\n",
							"\r\n",
							"# Adding the additional calculated/custom columns\r\n",
							"selected_df1 = selected_df1.withColumn(\"MeasurementType\", lit(\"Digital\"))\r\n",
							"#selected_df1 = selected_df1.withColumn(\"MeasurementYear\", lit(year))\r\n",
							"#selected_df1 = selected_df1.withColumn(\"MeasurementMonth\", lit(month))\r\n",
							"selected_df1 = selected_df1.withColumn(\"MeasurementDate\", to_date(selected_df1[\"Peildatum\"], \"dd/MMM/yy\").cast(DateType()))\r\n",
							"\r\n",
							"# Select the first row of the DataFrame and extract the last column value\r\n",
							"last_value = selected_df1.first()[-1]\r\n",
							"\r\n",
							"# Print the last column value to the console\r\n",
							"if last_value==None:\r\n",
							"    selected_df1 = selected_df1.drop(\"MeasurementDate\")\r\n",
							"    selected_df1 = selected_df1.withColumn(\"MeasurementDate\", to_date(selected_df1[\"Peildatum\"], \"MM/dd/yy\").cast(DateType()))\r\n",
							"\r\n",
							"last_value = selected_df1.first()[-1]\r\n",
							"if last_value==None:\r\n",
							"    selected_df1 = selected_df1.drop(\"MeasurementDate\")\r\n",
							"    selected_df1 = selected_df1.withColumn(\"MeasurementDate\", to_date(selected_df1[\"Peildatum\"], \"dd-MMM-yy\").cast(DateType()))\r\n",
							"\r\n",
							"# Drop the original col2 column\r\n",
							"selected_df1 = selected_df1.drop(\"Peildatum\")\r\n",
							"\r\n",
							"# Rename the new_col column to col2\r\n",
							"selected_df1 = selected_df1.withColumnRenamed(\"MeasurementDate\", \"Peildatum\")\r\n",
							"\r\n",
							"selected_df1 = selected_df1.withColumn(\"BenaderendVerbruik_VM_2017_Norm\", col(\"BenaderendVerbruik_VM_2017\"))\r\n",
							"selected_df1 = selected_df1.withColumn(\"BenaderendVerbruik_VM_2018_Norm\", col(\"BenaderendVerbruik_VM_2018\"))\r\n",
							"selected_df1 = selected_df1.withColumn(\"BenaderendVerbruik_VM_2019_Norm\", col(\"BenaderendVerbruik_VM_2019\"))\r\n",
							"selected_df1 = selected_df1.withColumn(\"BenaderendVerbruik_VM_2020_Norm\", col(\"BenaderendVerbruik_VM_2020\"))\r\n",
							"selected_df1 = selected_df1.withColumn(\"BenaderendVerbruik_VM_2021_Norm\", col(\"BenaderendVerbruik_VM_2021\"))\r\n",
							"\r\n",
							"selected_df1 = selected_df1.withColumn('WerkelijkVerbruik_RM_2017', regexp_replace(selected_df1['WerkelijkVerbruik_RM_2017'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('WerkelijkVerbruik_RM_2018', regexp_replace(selected_df1['WerkelijkVerbruik_RM_2018'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('WerkelijkVerbruik_RM_2019', regexp_replace(selected_df1['WerkelijkVerbruik_RM_2019'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('WerkelijkVerbruik_RM_2020', regexp_replace(selected_df1['WerkelijkVerbruik_RM_2020'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('WerkelijkVerbruik_RM_2021', regexp_replace(selected_df1['WerkelijkVerbruik_RM_2021'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('Gemiddeld_WerkelijkVerbruik', ((selected_df1['WerkelijkVerbruik_RM_2017']\\\r\n",
							"+ selected_df1['WerkelijkVerbruik_RM_2018'] + selected_df1['WerkelijkVerbruik_RM_2019'] + selected_df1['WerkelijkVerbruik_RM_2020']\\\r\n",
							"+ selected_df1['WerkelijkVerbruik_RM_2021'])/5))\r\n",
							"\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2017', regexp_replace(selected_df1['BenaderendVerbruik_VM_2017'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2018', regexp_replace(selected_df1['BenaderendVerbruik_VM_2018'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2019', regexp_replace(selected_df1['BenaderendVerbruik_VM_2019'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2020', regexp_replace(selected_df1['BenaderendVerbruik_VM_2020'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2021', regexp_replace(selected_df1['BenaderendVerbruik_VM_2021'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('Gemiddeld_BenaderendVerbruik', ((selected_df1['BenaderendVerbruik_VM_2017']\\\r\n",
							"+ selected_df1['BenaderendVerbruik_VM_2018'] + selected_df1['BenaderendVerbruik_VM_2019'] + selected_df1['BenaderendVerbruik_VM_2020']\\\r\n",
							"+ selected_df1['BenaderendVerbruik_VM_2021'])/5))\r\n",
							"\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2017_Norm', regexp_replace(selected_df1['BenaderendVerbruik_VM_2017_Norm'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2018_Norm', regexp_replace(selected_df1['BenaderendVerbruik_VM_2018_Norm'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2019_Norm', regexp_replace(selected_df1['BenaderendVerbruik_VM_2019_Norm'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2020_Norm', regexp_replace(selected_df1['BenaderendVerbruik_VM_2020_Norm'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('BenaderendVerbruik_VM_2021_Norm', regexp_replace(selected_df1['BenaderendVerbruik_VM_2021_Norm'], ',', '.'))\r\n",
							"selected_df1 = selected_df1.withColumn('Gemiddeld_BenaderendVerbruik_Norm', ((selected_df1['BenaderendVerbruik_VM_2017_Norm']\\\r\n",
							"+ selected_df1['BenaderendVerbruik_VM_2018_Norm'] + selected_df1['BenaderendVerbruik_VM_2019_Norm'] + selected_df1['BenaderendVerbruik_VM_2020_Norm']\\\r\n",
							"+ selected_df1['BenaderendVerbruik_VM_2021_Norm'])/5))\r\n",
							"\r\n",
							"selected_df1 = selected_df1.withColumn('Total_AantalToegangspunten', selected_df1['AantalToegangspunten_2017']\\\r\n",
							"+ selected_df1['AantalToegangspunten_2018'] + selected_df1['AantalToegangspunten_2019'] + selected_df1['AantalToegangspunten_2020']\\\r\n",
							"+ selected_df1['AantalToegangspunten_2021'])\r\n",
							"\r\n",
							"\r\n",
							"# Rearrange the columns\r\n",
							"selected_df1 = selected_df1.select('Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente', 'WerkelijkVerbruik_RM_2017'\\\r\n",
							", 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017', 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018'\\\r\n",
							", 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018', 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm'\\\r\n",
							", 'AantalToegangspunten_2019', 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
							", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021'\\\r\n",
							",'Gemiddeld_WerkelijkVerbruik','Gemiddeld_BenaderendVerbruik','Gemiddeld_BenaderendVerbruik_Norm','Total_AantalToegangspunten'\\\r\n",
							", 'MeasurementType') #, 'MeasurementYear', 'MeasurementMonth'"
						],
						"outputs": [],
						"execution_count": 59
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Checking the column name\r\n",
							"print(selected_df1.columns)\r\n",
							"\r\n",
							"spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\r\n",
							"\r\n",
							"# Displaying the top 5 rows\r\n",
							"display(selected_df1.limit(5))"
						],
						"outputs": [],
						"execution_count": 60
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Create a dynamic column delimiter using regex for DM\r\n",
							"import re\r\n",
							"def f_get_delimiter (source_path):\r\n",
							"    try:\r\n",
							"        headerlist = spark.sparkContext.textFile(source_path).take(1)\r\n",
							"        header_str = ''.join(headerlist)\r\n",
							"\r\n",
							"        results= re.search(\"(,|;|\\\\|)\",header_str)\r\n",
							"        return results.group()\r\n",
							"    except Exception as err:\r\n",
							"        print(\"Error Occured \", str(err))\r\n",
							"amr_Filename = 'abfss://rawdata@rawdevstorage.dfs.core.windows.net/%s/P6523_Verbruiken_DM_GEMEENTE_%s.csv' % (FolderName, FolderName_Without_Separator)\r\n",
							"amr_delimiter_type = (f_get_delimiter(amr_Filename))"
						],
						"outputs": [],
						"execution_count": 61
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false,
							"tags": []
						},
						"source": [
							"# Reading the second File (Digital Reading File)\r\n",
							"FileName = 'abfss://rawdata@rawdevstorage.dfs.core.windows.net/%s/P6523_Verbruiken_DM_GEMEENTE_%s.csv' % (FolderName,FolderName_Without_Separator)\r\n",
							"df2 = spark.read.load(FileName, format='csv', header=True,delimiter=amr_delimiter_type,inferSchema=True)\r\n",
							"\r\n",
							"# Remove duplicates\r\n",
							"df2 = df2.dropDuplicates()\r\n",
							"\r\n",
							"# Selecting the required columns\r\n",
							"selected_df2 = df2.select('Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente'\\\r\n",
							", 'WerkelijkVerbruik_RM_2017', 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017'\\\r\n",
							", 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018', 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018'\\\r\n",
							", 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm', 'AantalToegangspunten_2019'\\\r\n",
							", 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
							", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021')\r\n",
							"\r\n",
							"# Adding the additional calculated/custom columns\r\n",
							"selected_df2 = selected_df2.withColumn(\"MeasurementType\", lit(\"Digital\"))\r\n",
							"#selected_df2 = selected_df2.withColumn(\"MeasurementYear\", lit(year))\r\n",
							"#selected_df2 = selected_df2.withColumn(\"MeasurementMonth\", lit(month))\r\n",
							"selected_df2 = selected_df2.withColumn(\"MeasurementDate\", to_date(selected_df2[\"Peildatum\"], \"dd/MMM/yy\").cast(DateType()))\r\n",
							"\r\n",
							"# Select the first row of the DataFrame and extract the last column value\r\n",
							"last_value = selected_df2.first()[-1]\r\n",
							"\r\n",
							"# Print the last column value to the console\r\n",
							"if last_value==None:\r\n",
							"    selected_df2 = selected_df2.drop(\"MeasurementDate\")\r\n",
							"    selected_df2 = selected_df2.withColumn(\"MeasurementDate\", to_date(selected_df2[\"Peildatum\"], \"MM/dd/yy\").cast(DateType()))\r\n",
							"\r\n",
							"last_value = selected_df2.first()[-1]\r\n",
							"if last_value==None:\r\n",
							"    selected_df2 = selected_df2.drop(\"MeasurementDate\")\r\n",
							"    selected_df2 = selected_df2.withColumn(\"MeasurementDate\", to_date(selected_df2[\"Peildatum\"], \"dd-MMM-yy\").cast(DateType()))\r\n",
							"\r\n",
							"# Drop the original col2 column\r\n",
							"selected_df2 = selected_df2.drop(\"Peildatum\")\r\n",
							"\r\n",
							"# Rename the new_col column to col2\r\n",
							"selected_df2 = selected_df2.withColumnRenamed(\"MeasurementDate\", \"Peildatum\")\r\n",
							"\r\n",
							"selected_df2 = selected_df2.withColumn('WerkelijkVerbruik_RM_2017', regexp_replace(selected_df2['WerkelijkVerbruik_RM_2017'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('WerkelijkVerbruik_RM_2018', regexp_replace(selected_df2['WerkelijkVerbruik_RM_2018'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('WerkelijkVerbruik_RM_2019', regexp_replace(selected_df2['WerkelijkVerbruik_RM_2019'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('WerkelijkVerbruik_RM_2020', regexp_replace(selected_df2['WerkelijkVerbruik_RM_2020'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('WerkelijkVerbruik_RM_2021', regexp_replace(selected_df2['WerkelijkVerbruik_RM_2021'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('Gemiddeld_WerkelijkVerbruik', ((selected_df2['WerkelijkVerbruik_RM_2017']\\\r\n",
							"+ selected_df2['WerkelijkVerbruik_RM_2018'] + selected_df2['WerkelijkVerbruik_RM_2019'] + selected_df2['WerkelijkVerbruik_RM_2020']\\\r\n",
							"+ selected_df2['WerkelijkVerbruik_RM_2021'])/5))\r\n",
							"\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2017', regexp_replace(selected_df2['BenaderendVerbruik_VM_2017'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2018', regexp_replace(selected_df2['BenaderendVerbruik_VM_2018'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2019', regexp_replace(selected_df2['BenaderendVerbruik_VM_2019'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2020', regexp_replace(selected_df2['BenaderendVerbruik_VM_2020'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2021', regexp_replace(selected_df2['BenaderendVerbruik_VM_2021'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('Gemiddeld_BenaderendVerbruik', ((selected_df2['BenaderendVerbruik_VM_2017']\\\r\n",
							"+ selected_df2['BenaderendVerbruik_VM_2018'] + selected_df2['BenaderendVerbruik_VM_2019'] + selected_df2['BenaderendVerbruik_VM_2020']\\\r\n",
							"+ selected_df2['BenaderendVerbruik_VM_2021'])/5))\r\n",
							"\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2017_Norm', regexp_replace(selected_df2['BenaderendVerbruik_VM_2017_Norm'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2018_Norm', regexp_replace(selected_df2['BenaderendVerbruik_VM_2018_Norm'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2019_Norm', regexp_replace(selected_df2['BenaderendVerbruik_VM_2019_Norm'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2020_Norm', regexp_replace(selected_df2['BenaderendVerbruik_VM_2020_Norm'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('BenaderendVerbruik_VM_2021_Norm', regexp_replace(selected_df2['BenaderendVerbruik_VM_2021_Norm'], ',', '.'))\r\n",
							"selected_df2 = selected_df2.withColumn('Gemiddeld_BenaderendVerbruik_Norm', ((selected_df2['BenaderendVerbruik_VM_2017_Norm']\\\r\n",
							"+ selected_df2['BenaderendVerbruik_VM_2018_Norm'] + selected_df2['BenaderendVerbruik_VM_2019_Norm'] + selected_df2['BenaderendVerbruik_VM_2020_Norm']\\\r\n",
							"+ selected_df2['BenaderendVerbruik_VM_2021_Norm'])/5))\r\n",
							"\r\n",
							"selected_df2 = selected_df2.withColumn('Total_AantalToegangspunten', selected_df2['AantalToegangspunten_2017']\\\r\n",
							"+ selected_df2['AantalToegangspunten_2018'] + selected_df2['AantalToegangspunten_2019'] + selected_df2['AantalToegangspunten_2020']\\\r\n",
							"+ selected_df2['AantalToegangspunten_2021'])\r\n",
							"\r\n",
							"\r\n",
							"# Rearrange the columns\r\n",
							"selected_df2 = selected_df2.select('Trekkingsdatum', 'Peildatum', 'Markt', 'Leveringsadres_Postcode', 'Leveringsadres_Gemeente', 'WerkelijkVerbruik_RM_2017'\\\r\n",
							", 'BenaderendVerbruik_VM_2017', 'BenaderendVerbruik_VM_2017_Norm', 'AantalToegangspunten_2017', 'WerkelijkVerbruik_RM_2018', 'BenaderendVerbruik_VM_2018'\\\r\n",
							", 'BenaderendVerbruik_VM_2018_Norm', 'AantalToegangspunten_2018', 'WerkelijkVerbruik_RM_2019', 'BenaderendVerbruik_VM_2019', 'BenaderendVerbruik_VM_2019_Norm'\\\r\n",
							", 'AantalToegangspunten_2019', 'WerkelijkVerbruik_RM_2020', 'BenaderendVerbruik_VM_2020', 'BenaderendVerbruik_VM_2020_Norm', 'AantalToegangspunten_2020'\\\r\n",
							", 'WerkelijkVerbruik_RM_2021', 'BenaderendVerbruik_VM_2021', 'BenaderendVerbruik_VM_2021_Norm', 'AantalToegangspunten_2021'\\\r\n",
							",'Gemiddeld_WerkelijkVerbruik','Gemiddeld_BenaderendVerbruik','Gemiddeld_BenaderendVerbruik_Norm','Total_AantalToegangspunten'\\\r\n",
							", 'MeasurementType') #, 'MeasurementYear', 'MeasurementMonth'"
						],
						"outputs": [],
						"execution_count": 62
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Checking the column name\r\n",
							"print(selected_df2.columns)\r\n",
							"\r\n",
							"# Displaying the top 5 rows\r\n",
							"display(selected_df2.limit(5))"
						],
						"outputs": [],
						"execution_count": 63
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Checking the counts on each data frame\r\n",
							"print(selected_df1.count()) #Analogue Reading - 2660\r\n",
							"print(selected_df2.count()) #Digital Reading - 7005\r\n",
							""
						],
						"outputs": [],
						"execution_count": 64
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Creating a Group By to check the counts based on month, market and postal code\r\n",
							"from pyspark.sql.functions import count\r\n",
							"grouped_data1 = selected_df1.groupBy('Peildatum', 'Markt', 'Leveringsadres_Postcode')\r\n",
							"grouped_data2 = selected_df2.groupBy('Peildatum', 'Markt', 'Leveringsadres_Postcode')\r\n",
							"count_group_by1 = grouped_data1.agg(count(\"WerkelijkVerbruik_RM_2017\"))\r\n",
							"count_group_by1.show() #Analogue Reading Group BY\r\n",
							"count_group_by2 = grouped_data2.agg(count(\"WerkelijkVerbruik_RM_2017\"))\r\n",
							"count_group_by2.show() #Digital Reading Group By"
						],
						"outputs": [],
						"execution_count": 65
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Doing union operation to get a single dataframe combining Analogue and Digital measurement data\r\n",
							"df = selected_df2.unionAll(selected_df1)"
						],
						"outputs": [],
						"execution_count": 66
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Displaying the top 5 rows\r\n",
							"display(df.limit(5))\r\n",
							"\r\n",
							"# Checking the datatypes of the column\r\n",
							"df.dtypes"
						],
						"outputs": [],
						"execution_count": 67
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"file_path = 'abfss://output@rawdevstorage.dfs.core.windows.net/Electricity_Measurement_pyspark_union'\r\n",
							"write_format=\"delta\"\r\n",
							"partition_by=[\"Peildatum\"]\r\n",
							"mode_ = \"append\" #overwrite #append\r\n",
							"\r\n",
							"df\\\r\n",
							".write\\\r\n",
							".option(\"header\", \"true\")\\\r\n",
							".option(\"overwriteSchema\", \"true\")\\\r\n",
							".format(write_format)\\\r\n",
							".partitionBy(partition_by)\\\r\n",
							".mode(mode_)\\\r\n",
							".save(file_path)"
						],
						"outputs": [],
						"execution_count": 68
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Renaming the column names before join in order to avoid ambigious column names after the join\r\n",
							"new_column_names = [\"AM_\" + col_name for col_name in df.columns]\r\n",
							"selected_df1 = selected_df1.select([col(col_name).alias(new_col_name) for col_name, new_col_name in zip(df.columns, new_column_names)])\r\n",
							"new_column_names = [\"DM_\" + col_name for col_name in df.columns]\r\n",
							"selected_df2 = selected_df2.select([col(col_name).alias(new_col_name) for col_name, new_col_name in zip(df.columns, new_column_names)])"
						],
						"outputs": [],
						"execution_count": 69
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Doing a join operation to get a new data frame\r\n",
							"join_df = selected_df2.join(selected_df1, [selected_df1.AM_Markt == selected_df2.DM_Markt, selected_df1.AM_Leveringsadres_Postcode == selected_df2.DM_Leveringsadres_Postcode\\\r\n",
							", selected_df1.AM_Leveringsadres_Gemeente == selected_df2.DM_Leveringsadres_Gemeente, selected_df1.AM_Peildatum == selected_df2.DM_Peildatum],how='outer')\r\n",
							"\r\n",
							"# Selecting the required columns after the join operation\r\n",
							"# join_df = join_df.select('DM_Trekkingsdatum', 'DM_Peildatum', 'DM_Markt', 'DM_Leveringsadres_Postcode', 'DM_Leveringsadres_Gemeente'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2017', 'DM_BenaderendVerbruik_VM_2017', 'DM_BenaderendVerbruik_VM_2017_Norm', 'DM_AantalToegangspunten_2017'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2017', 'AM_BenaderendVerbruik_VM_2017', 'AM_BenaderendVerbruik_VM_2017_Norm', 'AM_AantalToegangspunten_2017'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2018', 'DM_BenaderendVerbruik_VM_2018', 'DM_BenaderendVerbruik_VM_2018_Norm', 'DM_AantalToegangspunten_2018'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2018', 'AM_BenaderendVerbruik_VM_2018', 'AM_BenaderendVerbruik_VM_2018_Norm', 'AM_AantalToegangspunten_2018'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2019', 'DM_BenaderendVerbruik_VM_2019', 'DM_BenaderendVerbruik_VM_2019_Norm', 'DM_AantalToegangspunten_2019'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2019', 'AM_BenaderendVerbruik_VM_2019', 'AM_BenaderendVerbruik_VM_2019_Norm', 'AM_AantalToegangspunten_2019'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2020', 'DM_BenaderendVerbruik_VM_2020', 'DM_BenaderendVerbruik_VM_2020_Norm', 'DM_AantalToegangspunten_2020'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2020', 'AM_BenaderendVerbruik_VM_2020', 'AM_BenaderendVerbruik_VM_2020_Norm', 'AM_AantalToegangspunten_2020'\\\r\n",
							"# , 'DM_WerkelijkVerbruik_RM_2021', 'DM_BenaderendVerbruik_VM_2021', 'DM_BenaderendVerbruik_VM_2021_Norm', 'DM_AantalToegangspunten_2021'\\\r\n",
							"# , 'AM_WerkelijkVerbruik_RM_2021', 'AM_BenaderendVerbruik_VM_2021', 'AM_BenaderendVerbruik_VM_2021_Norm', 'AM_AantalToegangspunten_2021'\\\r\n",
							"# , 'DM_Gemiddeld_WerkelijkVerbruik','DM_Gemiddeld_BenaderendVerbruik','DM_Gemiddeld_BenaderendVerbruik_Norm','DM_Total_AantalToegangspunten'\\\r\n",
							"# , 'AM_Gemiddeld_WerkelijkVerbruik','AM_Gemiddeld_BenaderendVerbruik','AM_Gemiddeld_BenaderendVerbruik_Norm','AM_Total_AantalToegangspunten'\r\n",
							"# , 'DM_MeasurementType') #, 'DM_MeasurementYear', 'DM_MeasurementMonth'"
						],
						"outputs": [],
						"execution_count": 70
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Printing the count of the join data frame\r\n",
							"print(join_df.count())\r\n",
							"\r\n",
							"# Displaying the top 5 rows\r\n",
							"display(join_df.limit(5))"
						],
						"outputs": [],
						"execution_count": 71
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"file_path = 'abfss://output@rawdevstorage.dfs.core.windows.net/Electricity_Measurement_pyspark_join'\r\n",
							"write_format=\"delta\"\r\n",
							"partition_by=[\"DM_Peildatum\"]\r\n",
							"mode_ = \"append\" #overwrite #append\r\n",
							"\r\n",
							"join_df\\\r\n",
							".write\\\r\n",
							".option(\"header\", \"true\")\\\r\n",
							".option(\"overwriteSchema\", \"true\")\\\r\n",
							".format(write_format)\\\r\n",
							".partitionBy(partition_by)\\\r\n",
							".mode(mode_)\\\r\n",
							".save(file_path)"
						],
						"outputs": [],
						"execution_count": 72
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Spark Structured Streaming and Delta Tables')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "ac37dcba-e05f-4bbc-971f-fc78f163d89c"
					}
				},
				"metadata": {
					"saveOutput": true,
					"synapse_widget": {
						"version": "0.1"
					},
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Spark Structured Streaming and Delta Tables\n",
							"\n",
							"Spark provides support for streaming data through *Spark Structured Streaming* and extends this support through *delta tables* that can be targets (*sinks*) or *sources* of streaming data.\n",
							"\n",
							"In this exercise, you'll use Spark to ingest a stream of data from a folder of JSON files that consists of simulated status messages from devices. In a real scenario, the data could come from some other real-time source, such as a Kafka queue or an Azure Event Hub.\n",
							"\n",
							"## Create a folder for the incoming stream of data\n",
							"\n",
							"1. Ensure this notebook is attached to your Spark pool (using this **Attach to** drop-down list above).\n",
							"2. Run the cell below to create a folder named **data** to which the simulated device data will be written.\n",
							"\n",
							"    > **Note**: The first cell may take some time to run because the Spark pool must be started.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from notebookutils import mssparkutils\n",
							"\n",
							"# Create a folder\n",
							"inputPath = '/data/'\n",
							"mssparkutils.fs.mkdirs(inputPath)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Use Spark Structured Streaming to query a stream of data\n",
							"\n",
							"1. Run the cell below to create a streaming dataframe that reads data from the folder based on a JSON schema that includes the name of the device and its status."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"from pyspark.sql.types import *\n",
							"from pyspark.sql.functions import *\n",
							"\n",
							"# Create a stream that reads data from the folder, using a JSON schema\n",
							"jsonSchema = StructType([\n",
							"  StructField(\"device\", StringType(), False),\n",
							"  StructField(\"status\", StringType(), False)\n",
							"])\n",
							"\n",
							"fileDF = spark.readStream.schema(jsonSchema).option(\"maxFilesPerTrigger\", 1).json(inputPath)\n",
							"\n",
							""
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"2. Wait for the cell above to complete.\n",
							"3. When the streaming dataframe has been created, you can apply a transformation query to aggregate the data and write the results to an output stream. Run the following code to filter the incoming stream for errors in the device data, and count the number of errors per device."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countDF = fileDF.filter(\"status == 'error'\").groupBy(\"device\").count()\n",
							"query = countDF.writeStream.format(\"memory\").queryName(\"counts\").outputMode(\"complete\").start()\n",
							"print('Streaming query started.')"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"4. The query output is streamed to an in-memory table. Run the cell below to use SQL to query this table and veiw the number of errors per device."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"microsoft": {
								"language": "sparksql"
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"%%sql\n",
							"select * from counts\n",
							""
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"5. Note that the query returns no data, because we haven't written any device status data there yet.\n",
							"6. Let's fix that by writing some status event data from a couple of simulated devices."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"device_data = '''{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev2\",\"status\":\"error\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"error\"}\n",
							"{\"device\":\"Dev2\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev2\",\"status\":\"error\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}'''\n",
							"\n",
							"mssparkutils.fs.put(inputPath + \"data.txt\", device_data, True)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"7. Run the SQL query again to see the aggregated error counts (if the query still returns no data, wait a few seconds and try again!) There should be one error for device 1, and two errors for device 2."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"microsoft": {
								"language": "sparksql"
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"%%sql\n",
							"select * from counts\n",
							""
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"8. Review the results, noting the number of errors. Then run the following code to write more device data."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"more_data = '''{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"error\"}\n",
							"{\"device\":\"Dev2\",\"status\":\"error\"}\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}'''\n",
							"\n",
							"mssparkutils.fs.put(inputPath + \"more-data.txt\", more_data, True)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"9. Run the SQL query again (waiting a few seconds if necessary) to see the new status events reflected in the aggregations. There should now be two errors for device 1, and three errors for device 2."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"microsoft": {
								"language": "sparksql"
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"%%sql\n",
							"select * from counts\n",
							""
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Create a delta table\n",
							"\n",
							"Azure Synapse Analytics supports the Linux Foundation *Delta Lake* architecture, which builds on Spark Structured Streaming to add support for transactions, versioning, and other useful capabilities.\n",
							"\n",
							"In particular, you can create *delta tables* as a target (or *sink*) for streaming data, or as a *source* of streaming data for downstream queries.\n",
							"\n",
							"To explore this, we'll write the streaming dataframe based on the **data** folder we created previously to a new delta table, which we'll define using a path to a location in the file system.\n",
							"\n",
							"1. Run the cell below to stream the folder data to a delta table."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"delta_table_path = inputPath + 'deltatable'\n",
							"stream = fileDF.writeStream.format(\"delta\").option(\"checkpointLocation\", inputPath + 'checkpoint').start(delta_table_path)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"2. Now run the next cell to query the delta table to see the data that has been streamed to it. If at first the query returns no data, wait a few seconds and run the cell again)."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df = spark.read.format(\"delta\").load(delta_table_path)\n",
							"display(df)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Delta tables enable you to use a feature named *time travel* to view the data at a previous point in time.\n",
							"\n",
							"4. Run the following query to retrieve the initial micro-batch of data that was streamed from the **devdata.txt** file. "
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
							"display(df)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"5. Now that you've finished exploring Spark Structured Streaming and delta tables, stop the stream of data and clean up the files used in this exercise."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false,
								"source_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"stream.stop()\n",
							"query.stop()\n",
							"print(\"Stream stopped\")\n",
							"mssparkutils.fs.rm(inputPath, True)"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/devpool')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 20
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 3,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.3",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": true,
				"annotations": []
			},
			"dependsOn": [],
			"location": "northeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Electricity_Measurement_pyspark_join')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "cmdevsynapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Electricity_Measurement_pyspark_join",
						"fileSystem": "output"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/cmdevsynapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Electricity_Measurement_pyspark_union')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Electricity_Measurement_pyspark_union",
				"linkedServiceName": {
					"referenceName": "cmdevsynapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Electricity_Measurement_pyspark_union",
						"fileSystem": "output"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/cmdevsynapse-WorkspaceDefaultStorage')]"
			]
		}
	]
}